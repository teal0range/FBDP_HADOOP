2021-10-07 14:14:49,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 14:14:49,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 14:14:50,277 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data
2021-10-07 14:14:50,348 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 14:14:50,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 14:14:50,410 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 14:14:50,563 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 14:14:50,574 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 14:14:50,578 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 14:14:50,579 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 14:14:50,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 14:14:50,600 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 14:14:50,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 14:14:50,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 14:14:50,643 INFO org.eclipse.jetty.util.log: Logging initialized @1002ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 14:14:50,722 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 14:14:50,729 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 14:14:50,736 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 14:14:50,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 14:14:50,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 14:14:50,738 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 14:14:50,759 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 40403
2021-10-07 14:14:50,760 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 14:14:50,812 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 14:14:50,812 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 14:14:50,814 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2021-10-07 14:14:50,822 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 14:14:50,822 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 14:14:50,865 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 14:14:50,874 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 14:14:50,880 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:40403}
2021-10-07 14:14:50,880 INFO org.eclipse.jetty.server.Server: Started @1239ms
2021-10-07 14:14:50,987 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 14:14:50,991 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 14:14:50,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 14:14:50,992 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 14:14:51,022 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 14:14:51,032 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 14:14:51,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 14:14:51,183 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 14:14:51,190 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 14:14:51,198 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2021-10-07 14:14:51,203 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 14:14:51,203 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 14:14:52,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:14:53,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:14:54,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:14:55,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:14:56,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:14:57,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:14:58,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:14:59,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:00,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:01,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:01,265 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:15:07,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:08,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:09,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:10,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:11,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:12,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:13,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:14,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:15,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:15,473 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-07 14:15:15,476 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at host1/172.19.0.2
************************************************************/
2021-10-07 14:15:38,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 14:15:38,668 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 14:15:38,950 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data
2021-10-07 14:15:39,022 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 14:15:39,083 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 14:15:39,083 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 14:15:39,231 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 14:15:39,242 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 14:15:39,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 14:15:39,246 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 14:15:39,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 14:15:39,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 14:15:39,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 14:15:39,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 14:15:39,303 INFO org.eclipse.jetty.util.log: Logging initialized @1001ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 14:15:39,376 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 14:15:39,381 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 14:15:39,389 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 14:15:39,391 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 14:15:39,391 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 14:15:39,391 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 14:15:39,410 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 41867
2021-10-07 14:15:39,411 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 14:15:39,464 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 14:15:39,465 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 14:15:39,466 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2021-10-07 14:15:39,473 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 14:15:39,474 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 14:15:39,515 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 14:15:39,523 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 14:15:39,531 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:41867}
2021-10-07 14:15:39,531 INFO org.eclipse.jetty.server.Server: Started @1229ms
2021-10-07 14:15:39,635 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 14:15:39,639 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 14:15:39,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 14:15:39,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 14:15:39,670 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 14:15:39,680 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 14:15:39,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 14:15:39,832 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 14:15:39,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 14:15:39,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2021-10-07 14:15:39,853 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 14:15:39,853 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 14:15:40,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:41,910 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:42,911 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:43,912 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:44,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:45,913 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:46,914 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:47,915 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:48,916 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:49,917 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:49,919 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:15:55,920 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:56,921 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:57,922 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:58,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:15:59,923 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:16:00,924 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:16:01,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:16:02,925 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:16:03,926 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:16:04,927 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:16:04,928 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:16:10,930 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:18,159 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 14:17:18,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 14:17:18,449 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/tmp/hadoop-root/dfs/data
2021-10-07 14:17:18,524 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 14:17:18,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 14:17:18,587 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 14:17:18,739 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 14:17:18,750 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 14:17:18,753 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 14:17:18,753 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 14:17:18,757 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 14:17:18,773 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 14:17:18,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 14:17:18,782 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 14:17:18,813 INFO org.eclipse.jetty.util.log: Logging initialized @998ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 14:17:18,896 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 14:17:18,902 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 14:17:18,909 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 14:17:18,911 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 14:17:18,911 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 14:17:18,911 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 14:17:18,930 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44407
2021-10-07 14:17:18,931 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 14:17:18,985 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 14:17:18,986 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 14:17:18,987 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2021-10-07 14:17:18,996 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 14:17:18,996 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 14:17:19,039 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 14:17:19,047 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 14:17:19,053 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:44407}
2021-10-07 14:17:19,054 INFO org.eclipse.jetty.server.Server: Started @1239ms
2021-10-07 14:17:19,160 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 14:17:19,165 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 14:17:19,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 14:17:19,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 14:17:19,196 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 14:17:19,204 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 14:17:19,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 14:17:19,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 14:17:19,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 14:17:19,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2021-10-07 14:17:19,371 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 14:17:19,371 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 14:17:20,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:21,429 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:22,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:23,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:24,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:25,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:26,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:27,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:28,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:29,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:29,436 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:17:35,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:36,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:37,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:38,439 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:39,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:40,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:41,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:42,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:43,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:44,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:44,444 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:17:50,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:51,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:52,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:53,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:54,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:55,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:56,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:57,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:58,453 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:59,454 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:17:59,455 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:18:05,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:06,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:07,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:08,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:09,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:10,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:11,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:12,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:13,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:14,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:14,464 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:18:20,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:21,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:22,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:23,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:24,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:25,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:26,470 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:27,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:28,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:29,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:29,474 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:18:35,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:36,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:37,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:38,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:39,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:40,478 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:41,479 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:42,480 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:43,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:44,481 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:44,482 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:18:50,483 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:51,485 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:52,486 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:53,487 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:54,488 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:55,489 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:56,490 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:57,491 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:58,492 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:59,493 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:18:59,493 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:19:05,494 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:06,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:07,496 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:08,497 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:09,498 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:10,499 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:11,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:12,500 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:13,501 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:14,502 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:14,503 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:19:20,504 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:21,505 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:22,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:23,506 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:24,507 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:25,508 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:26,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:27,509 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:28,510 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:29,511 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:29,512 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:19:35,513 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:36,514 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:37,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:38,515 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:39,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:40,516 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:41,517 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:42,518 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:43,519 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:44,520 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:44,520 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:19:50,522 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:51,523 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:52,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:53,524 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:54,525 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:55,526 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:56,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:57,527 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:58,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:59,529 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:19:59,530 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:20:05,531 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:06,532 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:07,533 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:08,534 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:09,535 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:10,536 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:11,537 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:12,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:13,538 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:14,539 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:14,539 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:20:20,541 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:21,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:22,543 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:23,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:24,544 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:25,545 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:26,546 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:27,547 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:28,548 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:29,549 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:29,549 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:20:35,550 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:36,551 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:37,552 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:38,553 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:39,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:40,554 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:41,555 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:42,556 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:43,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:44,557 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:44,558 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:20:50,560 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:51,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:52,561 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:53,562 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:54,563 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:55,564 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:56,565 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:57,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:58,566 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:59,567 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:20:59,568 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:21:05,569 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:06,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:07,570 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:08,571 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:09,572 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:10,573 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:11,574 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:12,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:13,575 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:14,576 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:14,577 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:21:20,578 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:21,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:22,580 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:23,581 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:24,582 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:25,583 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:26,584 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:27,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:28,585 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:29,586 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:29,587 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:21:35,587 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:36,588 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:37,589 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:38,590 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:39,591 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:40,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:41,592 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:42,593 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:43,594 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:44,595 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:44,595 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:21:50,596 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:51,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:52,597 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:53,598 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:54,599 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:55,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:56,600 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:57,601 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:58,602 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:59,603 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:21:59,603 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:22:05,604 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:06,605 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:07,606 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:08,607 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:09,608 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:10,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:11,609 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:12,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:13,610 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:14,612 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:14,612 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:22:20,614 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:21,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:22,615 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:23,616 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:24,617 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:25,618 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:26,619 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:27,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:28,620 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:29,621 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:29,622 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:22:35,623 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:36,624 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:37,625 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:38,626 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:39,627 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:40,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:41,628 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:42,629 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:43,630 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:44,631 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:44,632 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:22:50,632 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:51,633 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:52,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:53,634 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:54,635 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:55,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:56,636 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:57,637 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:58,638 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:59,639 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:22:59,640 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:23:05,641 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:06,642 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:07,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:08,643 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:09,644 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:10,645 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:11,646 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:12,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:13,647 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:14,648 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:14,648 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:23:20,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:21,650 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:22,651 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:23,652 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:24,653 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:25,654 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:26,655 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:27,656 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:28,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:29,657 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:29,658 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:23:35,659 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:36,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:37,660 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:38,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:39,662 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:40,663 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:41,664 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:42,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:43,665 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:44,666 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:44,666 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:23:50,667 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:51,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:52,668 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:53,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:54,669 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:55,670 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:56,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:57,671 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:58,672 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:59,673 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:23:59,673 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:24:05,674 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:06,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:07,676 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:08,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:09,677 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:10,678 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:11,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:12,679 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:13,680 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:14,681 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:14,681 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:24:20,682 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:21,683 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:22,684 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:23,685 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:24,686 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:25,687 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:26,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:27,688 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:28,689 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:29,690 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:29,690 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:24:35,692 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:36,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:37,693 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:38,694 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:39,695 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:40,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:41,696 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:42,697 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:43,698 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:44,699 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:44,699 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:24:50,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:51,701 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:52,702 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:53,703 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:54,704 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:55,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:56,705 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:57,706 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:58,707 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:59,708 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:24:59,709 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:25:05,709 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:06,710 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:07,711 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:08,712 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:09,713 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:10,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:11,714 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:12,715 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:13,716 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:14,717 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:14,718 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:25:20,719 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:21,720 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:22,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:23,721 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:24,722 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:25,723 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:26,724 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:27,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:28,725 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:29,726 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:29,726 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:25:35,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:36,727 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:37,728 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:38,729 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:39,730 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:40,731 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:41,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:42,732 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:43,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:44,733 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:44,734 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:25:50,735 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:51,736 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:52,737 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:53,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:54,738 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:55,739 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:56,740 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:57,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:58,741 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:59,742 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:25:59,742 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:26:05,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:06,744 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:07,745 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:08,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:09,746 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:10,747 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:11,748 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:12,749 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:13,750 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:14,751 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:14,752 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:26:20,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:21,753 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:22,754 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:23,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:24,755 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:25,756 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:26,757 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:27,758 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:28,759 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:29,760 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:29,761 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:26:35,761 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:36,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:37,762 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:38,763 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:39,764 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:40,765 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:41,766 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:42,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:43,767 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:44,768 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:44,769 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:26:50,770 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:51,771 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:52,772 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:53,773 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:54,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:55,774 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:56,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:57,775 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:58,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:59,776 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:26:59,777 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:27:05,778 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:06,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:07,779 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:08,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:09,780 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:10,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:11,781 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:12,782 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:13,783 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:14,784 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:14,784 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:27:19,376 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN, trace:
java.lang.Exception
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:214)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:225)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.getActorInfoMap(BPServiceActor.java:177)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBPServiceActorInfo(DataNode.java:3153)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:93)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-10-07 14:27:19,382 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool ID needed, but service not yet registered with NN, trace:
java.lang.Exception
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:214)
	at org.apache.hadoop.hdfs.server.datanode.BPOfferService.getBlockPoolId(BPOfferService.java:225)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getNamenodeAddresses(DataNode.java:3126)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:72)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:276)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:193)
	at com.sun.jmx.mbeanserver.ConvertingMethod.invokeWithOpenReturn(ConvertingMethod.java:175)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:117)
	at com.sun.jmx.mbeanserver.MXBeanIntrospector.invokeM2(MXBeanIntrospector.java:54)
	at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)
	at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)
	at com.sun.jmx.mbeanserver.MBeanSupport.getAttributes(MBeanSupport.java:213)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttributes(DefaultMBeanServerInterceptor.java:709)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttributes(JmxMBeanServer.java:705)
	at org.apache.hadoop.hdfs.server.common.MetricsLoggerTask.run(MetricsLoggerTask.java:93)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-10-07 14:27:20,785 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:21,786 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:22,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:23,787 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:24,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:25,788 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:26,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:27,789 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:28,790 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:29,791 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:29,791 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:27:35,792 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:36,793 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:37,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:38,794 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:39,795 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:40,796 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:41,797 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:42,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:43,798 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:44,799 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:44,799 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:27:50,800 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:51,801 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:52,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:53,802 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:54,803 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:55,804 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:56,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:57,805 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:58,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:59,806 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:27:59,807 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:28:05,808 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:06,809 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:07,810 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:08,811 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:09,812 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:10,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:11,813 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:12,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:13,814 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:14,815 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:14,816 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:28:20,817 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:21,818 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:22,819 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:23,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:24,820 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:25,821 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:26,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:27,822 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:28,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:29,823 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:29,824 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2021-10-07 14:28:35,826 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:36,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:37,827 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:38,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:39,828 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:40,829 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:41,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:42,830 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:43,831 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2021-10-07 14:28:44,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000
2021-10-07 14:28:44,039 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 14:28:44,046 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-root/dfs/data/in_use.lock acquired by nodename 301@host1
2021-10-07 14:28:44,048 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/tmp/hadoop-root/dfs/data is not formatted for namespace 1864844979. Formatting...
2021-10-07 14:28:44,048 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-b6274a4d-4b1c-4a13-be40-250d4346c6e0 for directory /tmp/hadoop-root/dfs/data 
2021-10-07 14:28:44,071 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:28:44,071 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-root/dfs/data/current/BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:28:44,072 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/tmp/hadoop-root/dfs/data and block pool id BP-492046972-172.19.0.2-1633616908198 is not formatted. Formatting ...
2021-10-07 14:28:44,072 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-492046972-172.19.0.2-1633616908198 directory /tmp/hadoop-root/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current
2021-10-07 14:28:44,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1864844979;bpid=BP-492046972-172.19.0.2-1633616908198;lv=-57;nsInfo=lv=-65;cid=CID-d833245b-8420-49b6-898e-c958ab56865f;nsid=1864844979;c=1633616908198;bpid=BP-492046972-172.19.0.2-1633616908198;dnuuid=null
2021-10-07 14:28:44,080 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID bf46e6e5-fef8-49da-8668-cbbcc5f61b14
2021-10-07 14:28:44,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-b6274a4d-4b1c-4a13-be40-250d4346c6e0
2021-10-07 14:28:44,156 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/tmp/hadoop-root/dfs/data, StorageType: DISK
2021-10-07 14:28:44,163 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 14:28:44,166 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 14:28:44,174 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:28:44,175 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-492046972-172.19.0.2-1633616908198 on volume /tmp/hadoop-root/dfs/data...
2021-10-07 14:28:44,206 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-492046972-172.19.0.2-1633616908198 on /tmp/hadoop-root/dfs/data: 31ms
2021-10-07 14:28:44,207 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-492046972-172.19.0.2-1633616908198: 32ms
2021-10-07 14:28:44,208 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-492046972-172.19.0.2-1633616908198 on volume /tmp/hadoop-root/dfs/data...
2021-10-07 14:28:44,208 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /tmp/hadoop-root/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/replicas doesn't exist 
2021-10-07 14:28:44,211 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-492046972-172.19.0.2-1633616908198 on volume /tmp/hadoop-root/dfs/data: 3ms
2021-10-07 14:28:44,211 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-492046972-172.19.0.2-1633616908198: 4ms
2021-10-07 14:28:44,211 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /tmp/hadoop-root/dfs/data
2021-10-07 14:28:44,219 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /tmp/hadoop-root/dfs/data
2021-10-07 14:28:44,222 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-492046972-172.19.0.2-1633616908198 on volume /tmp/hadoop-root/dfs/data
2021-10-07 14:28:44,224 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-b6274a4d-4b1c-4a13-be40-250d4346c6e0): finished scanning block pool BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:28:44,235 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 7:24 PM with interval of 21600000ms
2021-10-07 14:28:44,236 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-root/dfs/data, DS-b6274a4d-4b1c-4a13-be40-250d4346c6e0): no suitable block pools found to scan.  Waiting 1814399985 ms.
2021-10-07 14:28:44,240 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-492046972-172.19.0.2-1633616908198 (Datanode Uuid bf46e6e5-fef8-49da-8668-cbbcc5f61b14) service to localhost/127.0.0.1:9000 beginning handshake with NN
2021-10-07 14:28:44,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-492046972-172.19.0.2-1633616908198 (Datanode Uuid bf46e6e5-fef8-49da-8668-cbbcc5f61b14) service to localhost/127.0.0.1:9000 successfully registered with NN
2021-10-07 14:28:44,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 14:28:44,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xf0357e54af9c30a9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 92 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 14:28:44,516 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:29:08,363 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "host1/172.19.0.2"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:794)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:854)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1880)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1191)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1087)
2021-10-07 14:29:08,662 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-07 14:29:08,666 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at host1/172.19.0.2
************************************************************/
2021-10-07 14:29:44,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 14:29:44,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 14:29:45,108 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 14:29:45,182 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 14:29:45,247 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 14:29:45,247 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 14:29:45,414 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 14:29:45,426 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 14:29:45,429 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 14:29:45,429 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 14:29:45,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 14:29:45,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 14:29:45,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 14:29:45,451 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 14:29:45,495 INFO org.eclipse.jetty.util.log: Logging initialized @1087ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 14:29:45,577 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 14:29:45,583 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 14:29:45,590 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 14:29:45,592 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 14:29:45,592 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 14:29:45,592 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 14:29:45,612 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 45175
2021-10-07 14:29:45,613 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 14:29:45,670 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 14:29:45,670 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 14:29:45,671 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2021-10-07 14:29:45,682 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 14:29:45,682 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 14:29:45,732 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 14:29:45,740 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 14:29:45,746 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:45175}
2021-10-07 14:29:45,747 INFO org.eclipse.jetty.server.Server: Started @1339ms
2021-10-07 14:29:45,853 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 14:29:45,857 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 14:29:45,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 14:29:45,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 14:29:45,888 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 14:29:45,899 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 14:29:46,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 14:29:46,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 14:29:46,057 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 14:29:46,066 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 14:29:46,073 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 14:29:46,073 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 14:29:46,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 14:29:46,328 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 14:29:46,334 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 3135@host1
2021-10-07 14:29:46,335 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 1864844979. Formatting...
2021-10-07 14:29:46,335 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-5d431775-dd51-4d1c-a9c7-899b6b828d88 for directory /root/hadoop/dfs/data 
2021-10-07 14:29:46,354 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:29:46,354 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:29:46,355 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-492046972-172.19.0.2-1633616908198 is not formatted. Formatting ...
2021-10-07 14:29:46,355 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-492046972-172.19.0.2-1633616908198 directory /root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current
2021-10-07 14:29:46,360 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1864844979;bpid=BP-492046972-172.19.0.2-1633616908198;lv=-57;nsInfo=lv=-65;cid=CID-d833245b-8420-49b6-898e-c958ab56865f;nsid=1864844979;c=1633616908198;bpid=BP-492046972-172.19.0.2-1633616908198;dnuuid=null
2021-10-07 14:29:46,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 211d0692-9b3c-4016-8e84-7383bdd32d65
2021-10-07 14:29:46,437 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-5d431775-dd51-4d1c-a9c7-899b6b828d88
2021-10-07 14:29:46,437 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 14:29:46,442 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 14:29:46,444 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 14:29:46,452 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:29:46,453 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-492046972-172.19.0.2-1633616908198 on volume /root/hadoop/dfs/data...
2021-10-07 14:29:46,483 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-492046972-172.19.0.2-1633616908198 on /root/hadoop/dfs/data: 30ms
2021-10-07 14:29:46,484 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-492046972-172.19.0.2-1633616908198: 32ms
2021-10-07 14:29:46,485 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-492046972-172.19.0.2-1633616908198 on volume /root/hadoop/dfs/data...
2021-10-07 14:29:46,486 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/replicas doesn't exist 
2021-10-07 14:29:46,488 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-492046972-172.19.0.2-1633616908198 on volume /root/hadoop/dfs/data: 3ms
2021-10-07 14:29:46,488 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-492046972-172.19.0.2-1633616908198: 3ms
2021-10-07 14:29:46,488 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 14:29:46,499 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 14:29:46,503 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-492046972-172.19.0.2-1633616908198 on volume /root/hadoop/dfs/data
2021-10-07 14:29:46,505 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-5d431775-dd51-4d1c-a9c7-899b6b828d88): finished scanning block pool BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:29:46,518 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 2:54 PM with interval of 21600000ms
2021-10-07 14:29:46,518 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-5d431775-dd51-4d1c-a9c7-899b6b828d88): no suitable block pools found to scan.  Waiting 1814399985 ms.
2021-10-07 14:29:46,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-492046972-172.19.0.2-1633616908198 (Datanode Uuid 211d0692-9b3c-4016-8e84-7383bdd32d65) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 14:29:46,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-492046972-172.19.0.2-1633616908198 (Datanode Uuid 211d0692-9b3c-4016-8e84-7383bdd32d65) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 14:29:46,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 14:29:46,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x4fb1d734ce2d42a3,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 62 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 14:29:46,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-492046972-172.19.0.2-1633616908198
2021-10-07 14:30:29,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741825_1001 src: /172.19.0.2:39308 dest: /172.19.0.2:9866
2021-10-07 14:30:29,424 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39308, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2042146396_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741825_1001, duration(ns): 13446800
2021-10-07 14:30:29,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2021-10-07 14:30:34,592 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 316483
  getBytesOnDisk()  = 316483
  getVisibleLength()= 316483
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2021-10-07 14:30:34,594 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-492046972-172.19.0.2-1633616908198 blk_1073741825_1001 URI file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741825
2021-10-07 14:31:39,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741826_1002 src: /172.19.0.2:39322 dest: /172.19.0.2:9866
2021-10-07 14:31:39,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39322, dest: /172.19.0.2:9866, bytes: 1351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741826_1002, duration(ns): 9807300
2021-10-07 14:31:39,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:39,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741827_1003 src: /172.19.0.2:39324 dest: /172.19.0.2:9866
2021-10-07 14:31:39,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39324, dest: /172.19.0.2:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741827_1003, duration(ns): 3215300
2021-10-07 14:31:39,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:39,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741828_1004 src: /172.19.0.2:39326 dest: /172.19.0.2:9866
2021-10-07 14:31:39,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39326, dest: /172.19.0.2:9866, bytes: 3321, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741828_1004, duration(ns): 2598300
2021-10-07 14:31:39,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:39,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741829_1005 src: /172.19.0.2:39328 dest: /172.19.0.2:9866
2021-10-07 14:31:39,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39328, dest: /172.19.0.2:9866, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741829_1005, duration(ns): 2820500
2021-10-07 14:31:39,809 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:40,233 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741830_1006 src: /172.19.0.2:39330 dest: /172.19.0.2:9866
2021-10-07 14:31:40,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39330, dest: /172.19.0.2:9866, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741830_1006, duration(ns): 3193000
2021-10-07 14:31:40,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:40,259 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741831_1007 src: /172.19.0.2:39332 dest: /172.19.0.2:9866
2021-10-07 14:31:40,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39332, dest: /172.19.0.2:9866, bytes: 951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741831_1007, duration(ns): 2562200
2021-10-07 14:31:40,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:40,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741832_1008 src: /172.19.0.2:39334 dest: /172.19.0.2:9866
2021-10-07 14:31:40,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39334, dest: /172.19.0.2:9866, bytes: 2697, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741832_1008, duration(ns): 3065700
2021-10-07 14:31:40,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:40,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741833_1009 src: /172.19.0.2:39336 dest: /172.19.0.2:9866
2021-10-07 14:31:40,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39336, dest: /172.19.0.2:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741833_1009, duration(ns): 3018300
2021-10-07 14:31:40,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:40,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741834_1010 src: /172.19.0.2:39338 dest: /172.19.0.2:9866
2021-10-07 14:31:40,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39338, dest: /172.19.0.2:9866, bytes: 3880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741834_1010, duration(ns): 2774600
2021-10-07 14:31:40,343 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:40,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741835_1011 src: /172.19.0.2:39340 dest: /172.19.0.2:9866
2021-10-07 14:31:40,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39340, dest: /172.19.0.2:9866, bytes: 9213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741835_1011, duration(ns): 2713800
2021-10-07 14:31:40,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:40,788 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741836_1012 src: /172.19.0.2:39342 dest: /172.19.0.2:9866
2021-10-07 14:31:40,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39342, dest: /172.19.0.2:9866, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741836_1012, duration(ns): 2330200
2021-10-07 14:31:40,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:41,213 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741837_1013 src: /172.19.0.2:39344 dest: /172.19.0.2:9866
2021-10-07 14:31:41,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39344, dest: /172.19.0.2:9866, bytes: 983, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741837_1013, duration(ns): 2737000
2021-10-07 14:31:41,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:41,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741838_1014 src: /172.19.0.2:39346 dest: /172.19.0.2:9866
2021-10-07 14:31:41,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39346, dest: /172.19.0.2:9866, bytes: 5, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741838_1014, duration(ns): 3080500
2021-10-07 14:31:41,243 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:41,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741839_1015 src: /172.19.0.2:39348 dest: /172.19.0.2:9866
2021-10-07 14:31:41,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39348, dest: /172.19.0.2:9866, bytes: 6272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741839_1015, duration(ns): 2565700
2021-10-07 14:31:41,265 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:41,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741840_1016 src: /172.19.0.2:39350 dest: /172.19.0.2:9866
2021-10-07 14:31:41,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39350, dest: /172.19.0.2:9866, bytes: 3999, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741840_1016, duration(ns): 2447300
2021-10-07 14:31:41,690 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:42,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741841_1017 src: /172.19.0.2:39352 dest: /172.19.0.2:9866
2021-10-07 14:31:42,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39352, dest: /172.19.0.2:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741841_1017, duration(ns): 2384300
2021-10-07 14:31:42,116 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:42,540 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741842_1018 src: /172.19.0.2:39354 dest: /172.19.0.2:9866
2021-10-07 14:31:42,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39354, dest: /172.19.0.2:9866, bytes: 812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741842_1018, duration(ns): 3724500
2021-10-07 14:31:42,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:42,566 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741843_1019 src: /172.19.0.2:39356 dest: /172.19.0.2:9866
2021-10-07 14:31:42,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39356, dest: /172.19.0.2:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741843_1019, duration(ns): 3283700
2021-10-07 14:31:42,572 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:42,592 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741844_1020 src: /172.19.0.2:39358 dest: /172.19.0.2:9866
2021-10-07 14:31:42,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39358, dest: /172.19.0.2:9866, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741844_1020, duration(ns): 4358700
2021-10-07 14:31:42,599 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:43,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741845_1021 src: /172.19.0.2:39360 dest: /172.19.0.2:9866
2021-10-07 14:31:43,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39360, dest: /172.19.0.2:9866, bytes: 16287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741845_1021, duration(ns): 4391800
2021-10-07 14:31:43,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:43,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741846_1022 src: /172.19.0.2:39362 dest: /172.19.0.2:9866
2021-10-07 14:31:43,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39362, dest: /172.19.0.2:9866, bytes: 682, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741846_1022, duration(ns): 2944800
2021-10-07 14:31:43,056 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:43,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741847_1023 src: /172.19.0.2:39364 dest: /172.19.0.2:9866
2021-10-07 14:31:43,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39364, dest: /172.19.0.2:9866, bytes: 1092, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741847_1023, duration(ns): 3734300
2021-10-07 14:31:43,081 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:43,502 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741848_1024 src: /172.19.0.2:39366 dest: /172.19.0.2:9866
2021-10-07 14:31:43,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39366, dest: /172.19.0.2:9866, bytes: 867, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741848_1024, duration(ns): 2525500
2021-10-07 14:31:43,506 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:43,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741849_1025 src: /172.19.0.2:39368 dest: /172.19.0.2:9866
2021-10-07 14:31:43,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39368, dest: /172.19.0.2:9866, bytes: 14713, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741849_1025, duration(ns): 2817300
2021-10-07 14:31:43,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:43,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741850_1026 src: /172.19.0.2:39370 dest: /172.19.0.2:9866
2021-10-07 14:31:43,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39370, dest: /172.19.0.2:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741850_1026, duration(ns): 2499700
2021-10-07 14:31:43,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:43,971 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741851_1027 src: /172.19.0.2:39372 dest: /172.19.0.2:9866
2021-10-07 14:31:43,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39372, dest: /172.19.0.2:9866, bytes: 1860, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741851_1027, duration(ns): 3031600
2021-10-07 14:31:43,976 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:43,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741852_1028 src: /172.19.0.2:39374 dest: /172.19.0.2:9866
2021-10-07 14:31:43,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39374, dest: /172.19.0.2:9866, bytes: 11392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741852_1028, duration(ns): 2656400
2021-10-07 14:31:43,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:44,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741853_1029 src: /172.19.0.2:39376 dest: /172.19.0.2:9866
2021-10-07 14:31:44,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39376, dest: /172.19.0.2:9866, bytes: 1940, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741853_1029, duration(ns): 2518600
2021-10-07 14:31:44,422 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:44,842 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741854_1030 src: /172.19.0.2:39378 dest: /172.19.0.2:9866
2021-10-07 14:31:44,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39378, dest: /172.19.0.2:9866, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741854_1030, duration(ns): 3001000
2021-10-07 14:31:44,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:44,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741855_1031 src: /172.19.0.2:39380 dest: /172.19.0.2:9866
2021-10-07 14:31:44,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39380, dest: /172.19.0.2:9866, bytes: 1764, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741855_1031, duration(ns): 2308300
2021-10-07 14:31:44,868 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:44,884 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741856_1032 src: /172.19.0.2:39382 dest: /172.19.0.2:9866
2021-10-07 14:31:44,888 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39382, dest: /172.19.0.2:9866, bytes: 2250, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741856_1032, duration(ns): 2662300
2021-10-07 14:31:44,889 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2021-10-07 14:31:44,905 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741857_1033 src: /172.19.0.2:39384 dest: /172.19.0.2:9866
2021-10-07 14:31:44,909 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39384, dest: /172.19.0.2:9866, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2094384780_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741857_1033, duration(ns): 2320700
2021-10-07 14:31:44,910 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2021-10-07 14:32:10,596 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741834_1010 replica FinalizedReplica, blk_1073741834_1010, FINALIZED
  getNumBytes()     = 3880
  getBytesOnDisk()  = 3880
  getVisibleLength()= 3880
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741834 for deletion
2021-10-07 14:32:10,597 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-492046972-172.19.0.2-1633616908198 blk_1073741834_1010 URI file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741834
2021-10-07 14:33:38,636 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741858_1034 src: /172.19.0.2:39400 dest: /172.19.0.2:9866
2021-10-07 14:33:38,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39400, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_685333875_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741858_1034, duration(ns): 11738300
2021-10-07 14:33:38,649 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2021-10-07 14:33:38,761 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741859_1035 src: /172.19.0.2:39402 dest: /172.19.0.2:9866
2021-10-07 14:33:38,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39402, dest: /172.19.0.2:9866, bytes: 3621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_685333875_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741859_1035, duration(ns): 2290400
2021-10-07 14:33:38,766 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2021-10-07 14:33:38,783 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741860_1036 src: /172.19.0.2:39404 dest: /172.19.0.2:9866
2021-10-07 14:33:38,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39404, dest: /172.19.0.2:9866, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_685333875_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741860_1036, duration(ns): 1563900
2021-10-07 14:33:38,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2021-10-07 14:33:38,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741861_1037 src: /172.19.0.2:39406 dest: /172.19.0.2:9866
2021-10-07 14:33:38,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39406, dest: /172.19.0.2:9866, bytes: 200390, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_685333875_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741861_1037, duration(ns): 7304500
2021-10-07 14:33:38,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2021-10-07 14:54:29,529 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-492046972-172.19.0.2-1633616908198 Total blocks: 35, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-10-07 15:13:54,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741862_1038 src: /172.19.0.2:39586 dest: /172.19.0.2:9866
2021-10-07 15:13:54,768 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39586, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-472567628_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741862_1038, duration(ns): 12228600
2021-10-07 15:13:54,769 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2021-10-07 15:13:54,879 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741863_1039 src: /172.19.0.2:39588 dest: /172.19.0.2:9866
2021-10-07 15:13:54,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39588, dest: /172.19.0.2:9866, bytes: 3621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-472567628_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741863_1039, duration(ns): 1618000
2021-10-07 15:13:54,883 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2021-10-07 15:13:54,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741864_1040 src: /172.19.0.2:39590 dest: /172.19.0.2:9866
2021-10-07 15:13:54,901 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39590, dest: /172.19.0.2:9866, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-472567628_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741864_1040, duration(ns): 1513900
2021-10-07 15:13:54,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2021-10-07 15:13:55,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741865_1041 src: /172.19.0.2:39592 dest: /172.19.0.2:9866
2021-10-07 15:13:55,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39592, dest: /172.19.0.2:9866, bytes: 200338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-472567628_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741865_1041, duration(ns): 5602600
2021-10-07 15:13:55,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2021-10-07 15:14:03,425 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741866_1042 src: /172.19.0.2:39608 dest: /172.19.0.2:9866
2021-10-07 15:14:03,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39608, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_137083092_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741866_1042, duration(ns): 10797800
2021-10-07 15:14:03,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2021-10-07 15:14:22,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741867_1043 src: /172.19.0.2:39666 dest: /172.19.0.2:9866
2021-10-07 15:14:27,365 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1219ms
No GCs detected
2021-10-07 15:14:35,415 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 2047ms
No GCs detected
2021-10-07 15:15:05,955 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741868_1044 src: /172.19.0.2:39934 dest: /172.19.0.2:9866
2021-10-07 15:15:05,972 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39934, dest: /172.19.0.2:9866, bytes: 49342, op: HDFS_WRITE, cliID: DFSClient_attempt_1633616993781_0003_r_000000_0_-1299591164_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741868_1044, duration(ns): 16016200
2021-10-07 15:15:05,973 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2021-10-07 15:15:06,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39666, dest: /172.19.0.2:9866, bytes: 136318, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_137083092_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741867_1043, duration(ns): 43731313800
2021-10-07 15:15:06,075 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2021-10-07 15:15:06,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741869_1045 src: /172.19.0.2:39936 dest: /172.19.0.2:9866
2021-10-07 15:15:06,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39936, dest: /172.19.0.2:9866, bytes: 444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_137083092_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741869_1045, duration(ns): 2203000
2021-10-07 15:15:06,093 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2021-10-07 15:15:06,127 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741870_1046 src: /172.19.0.2:39940 dest: /172.19.0.2:9866
2021-10-07 15:15:06,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39940, dest: /172.19.0.2:9866, bytes: 136318, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_137083092_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741870_1046, duration(ns): 2480700
2021-10-07 15:15:06,131 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2021-10-07 15:15:06,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-492046972-172.19.0.2-1633616908198:blk_1073741871_1047 src: /172.19.0.2:39942 dest: /172.19.0.2:9866
2021-10-07 15:15:06,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39942, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_137083092_1, offset: 0, srvID: 211d0692-9b3c-4016-8e84-7383bdd32d65, blockid: BP-492046972-172.19.0.2-1633616908198:blk_1073741871_1047, duration(ns): 3012200
2021-10-07 15:15:06,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-492046972-172.19.0.2-1633616908198:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2021-10-07 15:15:10,053 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 replica FinalizedReplica, blk_1073741862_1038, FINALIZED
  getNumBytes()     = 316483
  getBytesOnDisk()  = 316483
  getVisibleLength()= 316483
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-10-07 15:15:10,054 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741863_1039 replica FinalizedReplica, blk_1073741863_1039, FINALIZED
  getNumBytes()     = 3621
  getBytesOnDisk()  = 3621
  getVisibleLength()= 3621
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741863 for deletion
2021-10-07 15:15:10,054 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-492046972-172.19.0.2-1633616908198 blk_1073741862_1038 URI file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741862
2021-10-07 15:15:10,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741864_1040 replica FinalizedReplica, blk_1073741864_1040, FINALIZED
  getNumBytes()     = 404
  getBytesOnDisk()  = 404
  getVisibleLength()= 404
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741864 for deletion
2021-10-07 15:15:10,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-492046972-172.19.0.2-1633616908198 blk_1073741863_1039 URI file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741863
2021-10-07 15:15:10,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741865_1041 replica FinalizedReplica, blk_1073741865_1041, FINALIZED
  getNumBytes()     = 200338
  getBytesOnDisk()  = 200338
  getVisibleLength()= 200338
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741865 for deletion
2021-10-07 15:15:10,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-492046972-172.19.0.2-1633616908198 blk_1073741864_1040 URI file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741864
2021-10-07 15:15:10,058 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741866_1042 replica FinalizedReplica, blk_1073741866_1042, FINALIZED
  getNumBytes()     = 231754
  getBytesOnDisk()  = 231754
  getVisibleLength()= 231754
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741866 for deletion
2021-10-07 15:15:10,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-492046972-172.19.0.2-1633616908198 blk_1073741865_1041 URI file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741865
2021-10-07 15:15:10,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741867_1043 replica FinalizedReplica, blk_1073741867_1043, FINALIZED
  getNumBytes()     = 136318
  getBytesOnDisk()  = 136318
  getVisibleLength()= 136318
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741867 for deletion
2021-10-07 15:15:10,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-492046972-172.19.0.2-1633616908198 blk_1073741866_1042 URI file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741866
2021-10-07 15:15:10,059 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-492046972-172.19.0.2-1633616908198 blk_1073741867_1043 URI file:/root/hadoop/dfs/data/current/BP-492046972-172.19.0.2-1633616908198/current/finalized/subdir0/subdir0/blk_1073741867
2021-10-07 16:14:42,581 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:14:42,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:14:42,937 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:14:43,030 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:14:43,111 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:14:43,111 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:14:43,304 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:14:43,317 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:14:43,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:14:43,322 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:14:43,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:14:43,348 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:14:43,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:14:43,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:14:43,393 INFO org.eclipse.jetty.util.log: Logging initialized @1248ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:14:43,487 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:14:43,494 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:14:43,506 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:14:43,510 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:14:43,510 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:14:43,510 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:14:43,569 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43063
2021-10-07 16:14:43,570 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:14:43,594 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:14:43,594 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:14:43,596 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2021-10-07 16:14:43,605 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:14:43,605 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:14:43,658 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:14:43,667 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:14:43,674 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:43063}
2021-10-07 16:14:43,674 INFO org.eclipse.jetty.server.Server: Started @1530ms
2021-10-07 16:14:43,797 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 16:14:43,802 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 16:14:43,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 16:14:43,802 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 16:14:43,838 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 16:14:43,849 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 16:14:44,022 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 16:14:44,037 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 16:14:44,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 16:14:44,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 16:14:44,059 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 16:14:44,061 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 16:14:44,263 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 16:14:44,266 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 16:14:44,271 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 603@host1
2021-10-07 16:14:44,272 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 1432328768. Formatting...
2021-10-07 16:14:44,273 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-c9dcfa18-5691-45a3-8e3a-7f142cae1b38 for directory /root/hadoop/dfs/data 
2021-10-07 16:14:44,297 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1037770201-172.19.0.2-1633623273147
2021-10-07 16:14:44,298 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-1037770201-172.19.0.2-1633623273147
2021-10-07 16:14:44,299 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-1037770201-172.19.0.2-1633623273147 is not formatted. Formatting ...
2021-10-07 16:14:44,299 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1037770201-172.19.0.2-1633623273147 directory /root/hadoop/dfs/data/current/BP-1037770201-172.19.0.2-1633623273147/current
2021-10-07 16:14:44,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1432328768;bpid=BP-1037770201-172.19.0.2-1633623273147;lv=-57;nsInfo=lv=-65;cid=CID-3d46fb31-85e9-42e5-bb3f-866be8ee88a2;nsid=1432328768;c=1633623273147;bpid=BP-1037770201-172.19.0.2-1633623273147;dnuuid=null
2021-10-07 16:14:44,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 3b15ce8e-0061-4888-b12f-4c2dacac8098
2021-10-07 16:14:44,409 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c9dcfa18-5691-45a3-8e3a-7f142cae1b38
2021-10-07 16:14:44,409 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 16:14:44,417 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 16:14:44,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 16:14:44,430 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1037770201-172.19.0.2-1633623273147
2021-10-07 16:14:44,431 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1037770201-172.19.0.2-1633623273147 on volume /root/hadoop/dfs/data...
2021-10-07 16:14:44,475 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1037770201-172.19.0.2-1633623273147 on /root/hadoop/dfs/data: 44ms
2021-10-07 16:14:44,475 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1037770201-172.19.0.2-1633623273147: 45ms
2021-10-07 16:14:44,490 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1037770201-172.19.0.2-1633623273147 on volume /root/hadoop/dfs/data...
2021-10-07 16:14:44,490 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-1037770201-172.19.0.2-1633623273147/current/replicas doesn't exist 
2021-10-07 16:14:44,495 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1037770201-172.19.0.2-1633623273147 on volume /root/hadoop/dfs/data: 5ms
2021-10-07 16:14:44,496 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1037770201-172.19.0.2-1633623273147: 18ms
2021-10-07 16:14:44,496 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 16:14:44,518 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 16:14:44,522 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1037770201-172.19.0.2-1633623273147 on volume /root/hadoop/dfs/data
2021-10-07 16:14:44,524 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-c9dcfa18-5691-45a3-8e3a-7f142cae1b38): finished scanning block pool BP-1037770201-172.19.0.2-1633623273147
2021-10-07 16:14:44,537 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-c9dcfa18-5691-45a3-8e3a-7f142cae1b38): no suitable block pools found to scan.  Waiting 1814399985 ms.
2021-10-07 16:14:44,539 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 7:25 PM with interval of 21600000ms
2021-10-07 16:14:44,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1037770201-172.19.0.2-1633623273147 (Datanode Uuid 3b15ce8e-0061-4888-b12f-4c2dacac8098) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 16:14:44,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1037770201-172.19.0.2-1633623273147 (Datanode Uuid 3b15ce8e-0061-4888-b12f-4c2dacac8098) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 16:14:44,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 16:14:44,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7a7f509a15bdb6f1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 74 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 16:14:44,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1037770201-172.19.0.2-1633623273147
2021-10-07 16:14:54,261 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1037770201-172.19.0.2-1633623273147:blk_1073741825_1001 src: /172.19.0.2:40224 dest: /172.19.0.2:9866
2021-10-07 16:14:54,377 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40224, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1574784578_1, offset: 0, srvID: 3b15ce8e-0061-4888-b12f-4c2dacac8098, blockid: BP-1037770201-172.19.0.2-1633623273147:blk_1073741825_1001, duration(ns): 46629400
2021-10-07 16:14:54,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1037770201-172.19.0.2-1633623273147:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2021-10-07 16:14:57,859 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-07 16:14:57,862 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at host1/172.19.0.2
************************************************************/
2021-10-07 16:15:28,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:15:28,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:15:28,939 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:15:29,023 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:15:29,094 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:15:29,094 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:15:29,285 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:15:29,302 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:15:29,306 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:15:29,306 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:15:29,310 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:15:29,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:15:29,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:15:29,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:15:29,378 INFO org.eclipse.jetty.util.log: Logging initialized @1236ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:15:29,465 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:15:29,471 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:15:29,482 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:15:29,484 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:15:29,484 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:15:29,484 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:15:29,514 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43085
2021-10-07 16:15:29,516 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:15:29,573 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:15:29,573 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:15:29,574 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2021-10-07 16:15:29,583 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:15:29,583 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:15:29,632 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:15:29,642 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:15:29,650 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:43085}
2021-10-07 16:15:29,650 INFO org.eclipse.jetty.server.Server: Started @1508ms
2021-10-07 16:15:29,773 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 16:15:29,779 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 16:15:29,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 16:15:29,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 16:15:29,813 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 16:15:29,824 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 16:15:30,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 16:15:30,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 16:15:30,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 16:15:30,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 16:15:30,041 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 16:15:30,052 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 16:15:30,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 16:15:30,253 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 16:15:30,260 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 603@host1
2021-10-07 16:15:30,261 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 2003375233. Formatting...
2021-10-07 16:15:30,261 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-0af399ab-86e7-47f6-ab04-a5cab5b4dfa6 for directory /root/hadoop/dfs/data 
2021-10-07 16:15:30,285 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-778816433-172.19.0.2-1633623318953
2021-10-07 16:15:30,285 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-778816433-172.19.0.2-1633623318953
2021-10-07 16:15:30,286 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-778816433-172.19.0.2-1633623318953 is not formatted. Formatting ...
2021-10-07 16:15:30,286 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-778816433-172.19.0.2-1633623318953 directory /root/hadoop/dfs/data/current/BP-778816433-172.19.0.2-1633623318953/current
2021-10-07 16:15:30,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2003375233;bpid=BP-778816433-172.19.0.2-1633623318953;lv=-57;nsInfo=lv=-65;cid=CID-6109dba1-5bf9-434f-adef-4f6788e0b038;nsid=2003375233;c=1633623318953;bpid=BP-778816433-172.19.0.2-1633623318953;dnuuid=null
2021-10-07 16:15:30,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 61fdf75f-687d-48eb-b1f4-692b020fe550
2021-10-07 16:15:30,397 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-0af399ab-86e7-47f6-ab04-a5cab5b4dfa6
2021-10-07 16:15:30,398 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 16:15:30,405 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 16:15:30,409 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 16:15:30,419 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-778816433-172.19.0.2-1633623318953
2021-10-07 16:15:30,420 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-778816433-172.19.0.2-1633623318953 on volume /root/hadoop/dfs/data...
2021-10-07 16:15:30,457 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-778816433-172.19.0.2-1633623318953 on /root/hadoop/dfs/data: 36ms
2021-10-07 16:15:30,457 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-778816433-172.19.0.2-1633623318953: 38ms
2021-10-07 16:15:30,469 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-778816433-172.19.0.2-1633623318953 on volume /root/hadoop/dfs/data...
2021-10-07 16:15:30,470 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-778816433-172.19.0.2-1633623318953/current/replicas doesn't exist 
2021-10-07 16:15:30,473 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-778816433-172.19.0.2-1633623318953 on volume /root/hadoop/dfs/data: 4ms
2021-10-07 16:15:30,473 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-778816433-172.19.0.2-1633623318953: 15ms
2021-10-07 16:15:30,474 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 16:15:30,501 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 16:15:30,506 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-778816433-172.19.0.2-1633623318953 on volume /root/hadoop/dfs/data
2021-10-07 16:15:30,508 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-0af399ab-86e7-47f6-ab04-a5cab5b4dfa6): finished scanning block pool BP-778816433-172.19.0.2-1633623318953
2021-10-07 16:15:30,522 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-0af399ab-86e7-47f6-ab04-a5cab5b4dfa6): no suitable block pools found to scan.  Waiting 1814399983 ms.
2021-10-07 16:15:30,523 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 7:11 PM with interval of 21600000ms
2021-10-07 16:15:30,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-778816433-172.19.0.2-1633623318953 (Datanode Uuid 61fdf75f-687d-48eb-b1f4-692b020fe550) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 16:15:30,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-778816433-172.19.0.2-1633623318953 (Datanode Uuid 61fdf75f-687d-48eb-b1f4-692b020fe550) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 16:15:30,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 16:15:30,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x4a8f6c122aeae1,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 71 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 16:15:30,770 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-778816433-172.19.0.2-1633623318953
2021-10-07 16:15:42,707 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: DestHost:destPort host1:9000 , LocalHost:localPort host1/172.19.0.2:0. Failed on local exception: java.io.IOException: Connection reset by peer
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:811)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:854)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:562)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1880)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1191)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1087)
2021-10-07 16:15:43,635 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-07 16:15:43,638 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at host1/172.19.0.2
************************************************************/
2021-10-07 16:15:56,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:15:56,589 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:15:56,953 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:15:57,038 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:15:57,112 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:15:57,112 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:15:57,298 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:15:57,311 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:15:57,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:15:57,314 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:15:57,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:15:57,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:15:57,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:15:57,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:15:57,382 INFO org.eclipse.jetty.util.log: Logging initialized @1200ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:15:57,471 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:15:57,477 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:15:57,486 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:15:57,488 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:15:57,488 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:15:57,488 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:15:57,553 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 39031
2021-10-07 16:15:57,554 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:15:57,579 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:15:57,579 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:15:57,581 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2021-10-07 16:15:57,592 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:15:57,593 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:15:57,645 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:15:57,655 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:15:57,663 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:39031}
2021-10-07 16:15:57,663 INFO org.eclipse.jetty.server.Server: Started @1481ms
2021-10-07 16:15:57,790 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 16:15:57,796 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 16:15:57,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 16:15:57,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 16:15:57,839 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 16:15:57,851 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 16:15:58,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 16:15:58,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 16:15:58,042 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 16:15:58,053 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 16:15:58,061 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 16:15:58,061 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 16:15:58,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 16:15:58,288 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 16:15:58,294 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 392@host1
2021-10-07 16:15:58,295 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 1832229394. Formatting...
2021-10-07 16:15:58,296 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-37ddbaac-9ca4-4cbb-b3a7-0ef8b45ff781 for directory /root/hadoop/dfs/data 
2021-10-07 16:15:58,319 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1288886236-172.19.0.2-1633623352845
2021-10-07 16:15:58,319 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-1288886236-172.19.0.2-1633623352845
2021-10-07 16:15:58,320 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-1288886236-172.19.0.2-1633623352845 is not formatted. Formatting ...
2021-10-07 16:15:58,320 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1288886236-172.19.0.2-1633623352845 directory /root/hadoop/dfs/data/current/BP-1288886236-172.19.0.2-1633623352845/current
2021-10-07 16:15:58,325 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1832229394;bpid=BP-1288886236-172.19.0.2-1633623352845;lv=-57;nsInfo=lv=-65;cid=CID-dc88858c-6daa-4d76-8dc5-cfa5ab9f69ee;nsid=1832229394;c=1633623352845;bpid=BP-1288886236-172.19.0.2-1633623352845;dnuuid=null
2021-10-07 16:15:58,327 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID f9893fd1-bf99-488c-ab13-5c78955368ed
2021-10-07 16:15:58,419 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-37ddbaac-9ca4-4cbb-b3a7-0ef8b45ff781
2021-10-07 16:15:58,419 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 16:15:58,425 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 16:15:58,429 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 16:15:58,438 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1288886236-172.19.0.2-1633623352845
2021-10-07 16:15:58,439 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1288886236-172.19.0.2-1633623352845 on volume /root/hadoop/dfs/data...
2021-10-07 16:15:58,480 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1288886236-172.19.0.2-1633623352845 on /root/hadoop/dfs/data: 41ms
2021-10-07 16:15:58,480 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1288886236-172.19.0.2-1633623352845: 42ms
2021-10-07 16:15:58,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1288886236-172.19.0.2-1633623352845 on volume /root/hadoop/dfs/data...
2021-10-07 16:15:58,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-1288886236-172.19.0.2-1633623352845/current/replicas doesn't exist 
2021-10-07 16:15:58,499 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1288886236-172.19.0.2-1633623352845 on volume /root/hadoop/dfs/data: 17ms
2021-10-07 16:15:58,499 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1288886236-172.19.0.2-1633623352845: 18ms
2021-10-07 16:15:58,499 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 16:15:58,514 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 16:15:58,518 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1288886236-172.19.0.2-1633623352845 on volume /root/hadoop/dfs/data
2021-10-07 16:15:58,520 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-37ddbaac-9ca4-4cbb-b3a7-0ef8b45ff781): finished scanning block pool BP-1288886236-172.19.0.2-1633623352845
2021-10-07 16:15:58,536 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 6:55 PM with interval of 21600000ms
2021-10-07 16:15:58,540 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-37ddbaac-9ca4-4cbb-b3a7-0ef8b45ff781): no suitable block pools found to scan.  Waiting 1814399978 ms.
2021-10-07 16:15:58,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1288886236-172.19.0.2-1633623352845 (Datanode Uuid f9893fd1-bf99-488c-ab13-5c78955368ed) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 16:15:58,606 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1288886236-172.19.0.2-1633623352845 (Datanode Uuid f9893fd1-bf99-488c-ab13-5c78955368ed) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 16:15:58,607 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 16:15:58,762 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xace77f3069f0e69,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 62 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 16:15:58,763 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1288886236-172.19.0.2-1633623352845
2021-10-07 16:16:16,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1288886236-172.19.0.2-1633623352845:blk_1073741825_1001 src: /172.19.0.2:40364 dest: /172.19.0.2:9866
2021-10-07 16:16:16,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40364, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-745257721_1, offset: 0, srvID: f9893fd1-bf99-488c-ab13-5c78955368ed, blockid: BP-1288886236-172.19.0.2-1633623352845:blk_1073741825_1001, duration(ns): 15104700
2021-10-07 16:16:16,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1288886236-172.19.0.2-1633623352845:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2021-10-07 16:16:19,611 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "host1/172.19.0.2"; destination host is: "host1":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:836)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:794)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1566)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy17.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:168)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:517)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:648)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:854)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1880)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1191)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1087)
2021-10-07 16:16:19,672 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-07 16:16:19,675 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at host1/172.19.0.2
************************************************************/
2021-10-07 16:17:17,837 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:17:17,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:17:18,201 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:17:18,289 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:17:18,364 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:17:18,364 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:17:18,553 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:17:18,570 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:17:18,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:17:18,574 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:17:18,577 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:17:18,595 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:17:18,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:17:18,597 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:17:18,635 INFO org.eclipse.jetty.util.log: Logging initialized @1204ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:17:18,721 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:17:18,732 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:17:18,750 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:17:18,752 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:17:18,752 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:17:18,752 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:17:18,778 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 36725
2021-10-07 16:17:18,779 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:17:18,844 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:17:18,844 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:17:18,845 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2021-10-07 16:17:18,854 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:17:18,855 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:17:18,905 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:17:18,914 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:17:18,921 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:36725}
2021-10-07 16:17:18,921 INFO org.eclipse.jetty.server.Server: Started @1491ms
2021-10-07 16:17:19,040 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 16:17:19,050 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 16:17:19,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 16:17:19,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 16:17:19,088 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 16:17:19,100 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 16:17:19,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 16:17:19,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 16:17:19,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 16:17:19,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 16:17:19,322 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 16:17:19,322 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 16:17:19,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 16:17:19,509 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 16:17:19,515 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 394@host1
2021-10-07 16:17:19,516 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 1396799105. Formatting...
2021-10-07 16:17:19,517 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-c4cbee79-ae9c-478b-8c21-9362a22c06b3 for directory /root/hadoop/dfs/data 
2021-10-07 16:17:19,545 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-376682021-172.19.0.2-1633623434073
2021-10-07 16:17:19,545 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073
2021-10-07 16:17:19,546 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-376682021-172.19.0.2-1633623434073 is not formatted. Formatting ...
2021-10-07 16:17:19,546 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-376682021-172.19.0.2-1633623434073 directory /root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current
2021-10-07 16:17:19,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1396799105;bpid=BP-376682021-172.19.0.2-1633623434073;lv=-57;nsInfo=lv=-65;cid=CID-087cb053-c38a-4432-bbd6-822606c9bb79;nsid=1396799105;c=1633623434073;bpid=BP-376682021-172.19.0.2-1633623434073;dnuuid=null
2021-10-07 16:17:19,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 53d0f647-f03a-425e-818d-e319512b23fa
2021-10-07 16:17:19,654 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-c4cbee79-ae9c-478b-8c21-9362a22c06b3
2021-10-07 16:17:19,654 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 16:17:19,660 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 16:17:19,664 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 16:17:19,673 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-376682021-172.19.0.2-1633623434073
2021-10-07 16:17:19,674 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-376682021-172.19.0.2-1633623434073 on volume /root/hadoop/dfs/data...
2021-10-07 16:17:19,723 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-376682021-172.19.0.2-1633623434073 on /root/hadoop/dfs/data: 49ms
2021-10-07 16:17:19,724 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-376682021-172.19.0.2-1633623434073: 50ms
2021-10-07 16:17:19,725 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-376682021-172.19.0.2-1633623434073 on volume /root/hadoop/dfs/data...
2021-10-07 16:17:19,725 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/replicas doesn't exist 
2021-10-07 16:17:19,742 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-376682021-172.19.0.2-1633623434073 on volume /root/hadoop/dfs/data: 17ms
2021-10-07 16:17:19,742 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-376682021-172.19.0.2-1633623434073: 18ms
2021-10-07 16:17:19,743 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 16:17:19,759 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 16:17:19,762 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-376682021-172.19.0.2-1633623434073 on volume /root/hadoop/dfs/data
2021-10-07 16:17:19,764 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-c4cbee79-ae9c-478b-8c21-9362a22c06b3): finished scanning block pool BP-376682021-172.19.0.2-1633623434073
2021-10-07 16:17:19,778 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-c4cbee79-ae9c-478b-8c21-9362a22c06b3): no suitable block pools found to scan.  Waiting 1814399984 ms.
2021-10-07 16:17:19,778 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 10:16 PM with interval of 21600000ms
2021-10-07 16:17:19,791 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-376682021-172.19.0.2-1633623434073 (Datanode Uuid 53d0f647-f03a-425e-818d-e319512b23fa) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 16:17:19,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-376682021-172.19.0.2-1633623434073 (Datanode Uuid 53d0f647-f03a-425e-818d-e319512b23fa) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 16:17:19,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 16:17:19,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd4e17b85260d7cdb,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 65 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 16:17:19,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-376682021-172.19.0.2-1633623434073
2021-10-07 16:17:34,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741825_1001 src: /172.19.0.2:40420 dest: /172.19.0.2:9866
2021-10-07 16:17:34,677 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40420, dest: /172.19.0.2:9866, bytes: 1351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741825_1001, duration(ns): 13243900
2021-10-07 16:17:34,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:35,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741826_1002 src: /172.19.0.2:40424 dest: /172.19.0.2:9866
2021-10-07 16:17:35,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40424, dest: /172.19.0.2:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741826_1002, duration(ns): 3656100
2021-10-07 16:17:35,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:35,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741827_1003 src: /172.19.0.2:40426 dest: /172.19.0.2:9866
2021-10-07 16:17:35,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40426, dest: /172.19.0.2:9866, bytes: 3321, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741827_1003, duration(ns): 2846700
2021-10-07 16:17:35,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:35,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741828_1004 src: /172.19.0.2:40430 dest: /172.19.0.2:9866
2021-10-07 16:17:35,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40430, dest: /172.19.0.2:9866, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741828_1004, duration(ns): 3149800
2021-10-07 16:17:35,986 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:36,409 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741829_1005 src: /172.19.0.2:40432 dest: /172.19.0.2:9866
2021-10-07 16:17:36,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40432, dest: /172.19.0.2:9866, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741829_1005, duration(ns): 2694400
2021-10-07 16:17:36,414 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:36,434 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741830_1006 src: /172.19.0.2:40434 dest: /172.19.0.2:9866
2021-10-07 16:17:36,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40434, dest: /172.19.0.2:9866, bytes: 951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741830_1006, duration(ns): 2569600
2021-10-07 16:17:36,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:36,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741831_1007 src: /172.19.0.2:40436 dest: /172.19.0.2:9866
2021-10-07 16:17:36,464 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40436, dest: /172.19.0.2:9866, bytes: 2697, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741831_1007, duration(ns): 3750500
2021-10-07 16:17:36,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:36,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741832_1008 src: /172.19.0.2:40438 dest: /172.19.0.2:9866
2021-10-07 16:17:36,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40438, dest: /172.19.0.2:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741832_1008, duration(ns): 3001200
2021-10-07 16:17:36,491 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:36,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741833_1009 src: /172.19.0.2:40440 dest: /172.19.0.2:9866
2021-10-07 16:17:36,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40440, dest: /172.19.0.2:9866, bytes: 3880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741833_1009, duration(ns): 7422300
2021-10-07 16:17:36,524 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:36,948 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741834_1010 src: /172.19.0.2:40444 dest: /172.19.0.2:9866
2021-10-07 16:17:36,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40444, dest: /172.19.0.2:9866, bytes: 9213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741834_1010, duration(ns): 3303100
2021-10-07 16:17:36,954 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741835_1011 src: /172.19.0.2:40446 dest: /172.19.0.2:9866
2021-10-07 16:17:37,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40446, dest: /172.19.0.2:9866, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741835_1011, duration(ns): 2515300
2021-10-07 16:17:37,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741836_1012 src: /172.19.0.2:40448 dest: /172.19.0.2:9866
2021-10-07 16:17:37,406 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40448, dest: /172.19.0.2:9866, bytes: 983, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741836_1012, duration(ns): 2585100
2021-10-07 16:17:37,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741837_1013 src: /172.19.0.2:40450 dest: /172.19.0.2:9866
2021-10-07 16:17:37,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40450, dest: /172.19.0.2:9866, bytes: 12, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741837_1013, duration(ns): 2477200
2021-10-07 16:17:37,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741838_1014 src: /172.19.0.2:40452 dest: /172.19.0.2:9866
2021-10-07 16:17:37,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40452, dest: /172.19.0.2:9866, bytes: 6272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741838_1014, duration(ns): 3530200
2021-10-07 16:17:37,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741839_1015 src: /172.19.0.2:40454 dest: /172.19.0.2:9866
2021-10-07 16:17:37,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40454, dest: /172.19.0.2:9866, bytes: 3999, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741839_1015, duration(ns): 3758000
2021-10-07 16:17:37,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741840_1016 src: /172.19.0.2:40458 dest: /172.19.0.2:9866
2021-10-07 16:17:37,920 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40458, dest: /172.19.0.2:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741840_1016, duration(ns): 3297200
2021-10-07 16:17:37,921 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,945 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741841_1017 src: /172.19.0.2:40460 dest: /172.19.0.2:9866
2021-10-07 16:17:37,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40460, dest: /172.19.0.2:9866, bytes: 812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741841_1017, duration(ns): 3148900
2021-10-07 16:17:37,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,969 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741842_1018 src: /172.19.0.2:40462 dest: /172.19.0.2:9866
2021-10-07 16:17:37,974 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40462, dest: /172.19.0.2:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741842_1018, duration(ns): 3517000
2021-10-07 16:17:37,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:37,995 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741843_1019 src: /172.19.0.2:40464 dest: /172.19.0.2:9866
2021-10-07 16:17:37,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40464, dest: /172.19.0.2:9866, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741843_1019, duration(ns): 3438700
2021-10-07 16:17:38,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:38,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741844_1020 src: /172.19.0.2:40466 dest: /172.19.0.2:9866
2021-10-07 16:17:38,023 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40466, dest: /172.19.0.2:9866, bytes: 16287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741844_1020, duration(ns): 3673000
2021-10-07 16:17:38,024 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:38,041 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741845_1021 src: /172.19.0.2:40468 dest: /172.19.0.2:9866
2021-10-07 16:17:38,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40468, dest: /172.19.0.2:9866, bytes: 682, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741845_1021, duration(ns): 2795300
2021-10-07 16:17:38,046 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:38,466 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741846_1022 src: /172.19.0.2:40470 dest: /172.19.0.2:9866
2021-10-07 16:17:38,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40470, dest: /172.19.0.2:9866, bytes: 1040, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741846_1022, duration(ns): 3446500
2021-10-07 16:17:38,472 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:38,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741847_1023 src: /172.19.0.2:40474 dest: /172.19.0.2:9866
2021-10-07 16:17:38,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40474, dest: /172.19.0.2:9866, bytes: 867, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741847_1023, duration(ns): 2797500
2021-10-07 16:17:38,898 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:38,919 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741848_1024 src: /172.19.0.2:40476 dest: /172.19.0.2:9866
2021-10-07 16:17:38,924 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40476, dest: /172.19.0.2:9866, bytes: 14713, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741848_1024, duration(ns): 2957800
2021-10-07 16:17:38,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:39,350 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741849_1025 src: /172.19.0.2:40478 dest: /172.19.0.2:9866
2021-10-07 16:17:39,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40478, dest: /172.19.0.2:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741849_1025, duration(ns): 3508400
2021-10-07 16:17:39,355 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:39,775 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741850_1026 src: /172.19.0.2:40482 dest: /172.19.0.2:9866
2021-10-07 16:17:39,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40482, dest: /172.19.0.2:9866, bytes: 1860, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741850_1026, duration(ns): 2730500
2021-10-07 16:17:39,780 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:39,803 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741851_1027 src: /172.19.0.2:40484 dest: /172.19.0.2:9866
2021-10-07 16:17:39,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40484, dest: /172.19.0.2:9866, bytes: 11392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741851_1027, duration(ns): 3464400
2021-10-07 16:17:39,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:40,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741852_1028 src: /172.19.0.2:40486 dest: /172.19.0.2:9866
2021-10-07 16:17:40,231 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40486, dest: /172.19.0.2:9866, bytes: 1940, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741852_1028, duration(ns): 2606400
2021-10-07 16:17:40,232 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:40,653 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741853_1029 src: /172.19.0.2:40490 dest: /172.19.0.2:9866
2021-10-07 16:17:40,659 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40490, dest: /172.19.0.2:9866, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741853_1029, duration(ns): 4749600
2021-10-07 16:17:40,660 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:40,681 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741854_1030 src: /172.19.0.2:40492 dest: /172.19.0.2:9866
2021-10-07 16:17:40,685 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40492, dest: /172.19.0.2:9866, bytes: 1764, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741854_1030, duration(ns): 2474500
2021-10-07 16:17:40,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:41,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741855_1031 src: /172.19.0.2:40494 dest: /172.19.0.2:9866
2021-10-07 16:17:41,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40494, dest: /172.19.0.2:9866, bytes: 2250, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741855_1031, duration(ns): 2609400
2021-10-07 16:17:41,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:41,531 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741856_1032 src: /172.19.0.2:40496 dest: /172.19.0.2:9866
2021-10-07 16:17:41,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40496, dest: /172.19.0.2:9866, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1176757239_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741856_1032, duration(ns): 3854400
2021-10-07 16:17:41,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:45,077 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741857_1033 src: /172.19.0.2:40504 dest: /172.19.0.2:9866
2021-10-07 16:17:45,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40504, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_111574395_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741857_1033, duration(ns): 9978800
2021-10-07 16:17:45,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:45,212 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741858_1034 src: /172.19.0.2:40506 dest: /172.19.0.2:9866
2021-10-07 16:17:45,317 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40506, dest: /172.19.0.2:9866, bytes: 3621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_111574395_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741858_1034, duration(ns): 13747700
2021-10-07 16:17:45,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[172.19.0.3:9866] terminating
2021-10-07 16:17:45,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741859_1035 src: /172.19.0.2:40510 dest: /172.19.0.2:9866
2021-10-07 16:17:45,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40510, dest: /172.19.0.2:9866, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_111574395_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741859_1035, duration(ns): 2039200
2021-10-07 16:17:45,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:45,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741860_1036 src: /172.19.0.2:40512 dest: /172.19.0.2:9866
2021-10-07 16:17:45,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40512, dest: /172.19.0.2:9866, bytes: 200338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_111574395_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741860_1036, duration(ns): 8105200
2021-10-07 16:17:45,853 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:46,843 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 replica FinalizedReplica, blk_1073741833_1009, FINALIZED
  getNumBytes()     = 3880
  getBytesOnDisk()  = 3880
  getVisibleLength()= 3880
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-10-07 16:17:46,844 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-376682021-172.19.0.2-1633623434073 blk_1073741833_1009 URI file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741833
2021-10-07 16:17:49,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.19.0.2:9866, datanodeUuid=53d0f647-f03a-425e-818d-e319512b23fa, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-087cb053-c38a-4432-bbd6-822606c9bb79;nsid=1396799105;c=1633623434073) Starting thread to transfer BP-376682021-172.19.0.2-1633623434073:blk_1073741857_1033 to 172.19.0.3:9866 
2021-10-07 16:17:49,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at host1:9866: Transmitted BP-376682021-172.19.0.2-1633623434073:blk_1073741857_1033 (numBytes=316483) to /172.19.0.3:9866
2021-10-07 16:17:51,385 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741861_1037 src: /172.19.0.2:40530 dest: /172.19.0.2:9866
2021-10-07 16:17:51,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40530, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1856450869_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741861_1037, duration(ns): 7308300
2021-10-07 16:17:51,394 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2021-10-07 16:17:57,507 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741862_1038 src: /172.19.0.2:40582 dest: /172.19.0.2:9866
2021-10-07 16:18:20,691 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741863_1039 src: /172.19.0.2:40832 dest: /172.19.0.2:9866
2021-10-07 16:18:20,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40832, dest: /172.19.0.2:9866, bytes: 49298, op: HDFS_WRITE, cliID: DFSClient_attempt_1633623447272_0001_r_000000_0_-1789942598_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741863_1039, duration(ns): 9936700
2021-10-07 16:18:20,702 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2021-10-07 16:18:20,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40582, dest: /172.19.0.2:9866, bytes: 136181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1856450869_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741862_1038, duration(ns): 23289160300
2021-10-07 16:18:20,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2021-10-07 16:18:20,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741864_1040 src: /172.19.0.2:40836 dest: /172.19.0.2:9866
2021-10-07 16:18:20,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40836, dest: /172.19.0.2:9866, bytes: 444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1856450869_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741864_1040, duration(ns): 1868000
2021-10-07 16:18:20,813 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2021-10-07 16:18:20,841 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741865_1041 src: /172.19.0.2:40840 dest: /172.19.0.2:9866
2021-10-07 16:18:20,845 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40840, dest: /172.19.0.2:9866, bytes: 136181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1856450869_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741865_1041, duration(ns): 2564100
2021-10-07 16:18:20,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2021-10-07 16:18:20,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-376682021-172.19.0.2-1633623434073:blk_1073741866_1042 src: /172.19.0.2:40842 dest: /172.19.0.2:9866
2021-10-07 16:18:20,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40842, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1856450869_1, offset: 0, srvID: 53d0f647-f03a-425e-818d-e319512b23fa, blockid: BP-376682021-172.19.0.2-1633623434073:blk_1073741866_1042, duration(ns): 2478100
2021-10-07 16:18:20,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-376682021-172.19.0.2-1633623434073:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2021-10-07 16:18:25,837 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 replica FinalizedReplica, blk_1073741857_1033, FINALIZED
  getNumBytes()     = 316483
  getBytesOnDisk()  = 316483
  getVisibleLength()= 316483
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-10-07 16:18:25,838 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 replica FinalizedReplica, blk_1073741858_1034, FINALIZED
  getNumBytes()     = 3621
  getBytesOnDisk()  = 3621
  getVisibleLength()= 3621
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2021-10-07 16:18:25,838 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-376682021-172.19.0.2-1633623434073 blk_1073741857_1033 URI file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741857
2021-10-07 16:18:25,838 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 replica FinalizedReplica, blk_1073741859_1035, FINALIZED
  getNumBytes()     = 404
  getBytesOnDisk()  = 404
  getVisibleLength()= 404
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-10-07 16:18:25,838 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 replica FinalizedReplica, blk_1073741860_1036, FINALIZED
  getNumBytes()     = 200338
  getBytesOnDisk()  = 200338
  getVisibleLength()= 200338
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-10-07 16:18:25,838 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-376682021-172.19.0.2-1633623434073 blk_1073741858_1034 URI file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741858
2021-10-07 16:18:25,838 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 replica FinalizedReplica, blk_1073741861_1037, FINALIZED
  getNumBytes()     = 231754
  getBytesOnDisk()  = 231754
  getVisibleLength()= 231754
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-10-07 16:18:25,838 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-376682021-172.19.0.2-1633623434073 blk_1073741859_1035 URI file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741859
2021-10-07 16:18:25,839 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 replica FinalizedReplica, blk_1073741862_1038, FINALIZED
  getNumBytes()     = 136181
  getBytesOnDisk()  = 136181
  getVisibleLength()= 136181
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-10-07 16:18:25,839 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-376682021-172.19.0.2-1633623434073 blk_1073741860_1036 URI file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741860
2021-10-07 16:18:25,839 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-376682021-172.19.0.2-1633623434073 blk_1073741861_1037 URI file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741861
2021-10-07 16:18:25,839 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-376682021-172.19.0.2-1633623434073 blk_1073741862_1038 URI file:/root/hadoop/dfs/data/current/BP-376682021-172.19.0.2-1633623434073/current/finalized/subdir0/subdir0/blk_1073741862
2021-10-07 16:18:28,612 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-07 16:18:28,615 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at host1/172.19.0.2
************************************************************/
2021-10-07 16:19:59,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:19:59,267 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:19:59,786 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:19:59,914 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:20:00,008 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:20:00,008 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:20:00,296 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:20:00,315 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:20:00,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:20:00,321 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:20:00,326 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:20:00,354 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:20:00,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:20:00,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:20:00,428 INFO org.eclipse.jetty.util.log: Logging initialized @1742ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:20:00,557 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:20:00,566 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:20:00,578 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:20:00,581 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:20:00,582 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:20:00,582 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:20:00,621 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 42131
2021-10-07 16:20:00,622 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:20:00,750 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:20:00,751 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:20:00,753 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2021-10-07 16:20:00,766 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:20:00,768 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:20:00,835 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:20:00,849 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:20:00,859 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:42131}
2021-10-07 16:20:00,859 INFO org.eclipse.jetty.server.Server: Started @2173ms
2021-10-07 16:20:01,042 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 16:20:01,049 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 16:20:01,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 16:20:01,051 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 16:20:01,106 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 16:20:01,121 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 16:20:01,399 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 16:20:01,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 16:20:01,436 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 16:20:01,454 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 16:20:01,529 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 16:20:01,541 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 16:20:01,819 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 16:20:01,822 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 16:20:01,828 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 400@host1
2021-10-07 16:20:01,829 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 1538236608. Formatting...
2021-10-07 16:20:01,830 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-b9a39d2e-28f1-4a24-a1cc-a3a6a323bc87 for directory /root/hadoop/dfs/data 
2021-10-07 16:20:01,858 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-120179873-172.19.0.2-1633623595293
2021-10-07 16:20:01,858 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293
2021-10-07 16:20:01,859 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-120179873-172.19.0.2-1633623595293 is not formatted. Formatting ...
2021-10-07 16:20:01,859 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-120179873-172.19.0.2-1633623595293 directory /root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current
2021-10-07 16:20:01,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1538236608;bpid=BP-120179873-172.19.0.2-1633623595293;lv=-57;nsInfo=lv=-65;cid=CID-49f65dcc-f3ca-4aa8-b18f-993b6cb1b4f1;nsid=1538236608;c=1633623595293;bpid=BP-120179873-172.19.0.2-1633623595293;dnuuid=null
2021-10-07 16:20:01,872 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID df9c3895-b2fb-487d-9609-4ab82a050cb2
2021-10-07 16:20:01,993 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-b9a39d2e-28f1-4a24-a1cc-a3a6a323bc87
2021-10-07 16:20:01,994 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 16:20:02,000 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 16:20:02,004 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 16:20:02,015 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-120179873-172.19.0.2-1633623595293
2021-10-07 16:20:02,020 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-120179873-172.19.0.2-1633623595293 on volume /root/hadoop/dfs/data...
2021-10-07 16:20:02,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-120179873-172.19.0.2-1633623595293 on /root/hadoop/dfs/data: 44ms
2021-10-07 16:20:02,064 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-120179873-172.19.0.2-1633623595293: 49ms
2021-10-07 16:20:02,072 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-120179873-172.19.0.2-1633623595293 on volume /root/hadoop/dfs/data...
2021-10-07 16:20:02,082 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/replicas doesn't exist 
2021-10-07 16:20:02,108 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-120179873-172.19.0.2-1633623595293 on volume /root/hadoop/dfs/data: 27ms
2021-10-07 16:20:02,108 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-120179873-172.19.0.2-1633623595293: 42ms
2021-10-07 16:20:02,109 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 16:20:02,121 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 16:20:02,125 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-120179873-172.19.0.2-1633623595293 on volume /root/hadoop/dfs/data
2021-10-07 16:20:02,131 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-b9a39d2e-28f1-4a24-a1cc-a3a6a323bc87): finished scanning block pool BP-120179873-172.19.0.2-1633623595293
2021-10-07 16:20:02,151 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 5:11 PM with interval of 21600000ms
2021-10-07 16:20:02,154 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-b9a39d2e-28f1-4a24-a1cc-a3a6a323bc87): no suitable block pools found to scan.  Waiting 1814399971 ms.
2021-10-07 16:20:02,160 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-120179873-172.19.0.2-1633623595293 (Datanode Uuid df9c3895-b2fb-487d-9609-4ab82a050cb2) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 16:20:02,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-120179873-172.19.0.2-1633623595293 (Datanode Uuid df9c3895-b2fb-487d-9609-4ab82a050cb2) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 16:20:02,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 16:20:02,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xbdcb6055bc63d1db,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 78 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 16:20:02,498 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-120179873-172.19.0.2-1633623595293
2021-10-07 16:20:17,925 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741825_1001 src: /172.19.0.2:40928 dest: /172.19.0.2:9866
2021-10-07 16:20:17,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40928, dest: /172.19.0.2:9866, bytes: 1351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741825_1001, duration(ns): 13002500
2021-10-07 16:20:17,958 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:18,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741826_1002 src: /172.19.0.2:40936 dest: /172.19.0.2:9866
2021-10-07 16:20:18,407 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40936, dest: /172.19.0.2:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741826_1002, duration(ns): 2972700
2021-10-07 16:20:18,408 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:18,831 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741827_1003 src: /172.19.0.2:40938 dest: /172.19.0.2:9866
2021-10-07 16:20:18,835 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40938, dest: /172.19.0.2:9866, bytes: 3321, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741827_1003, duration(ns): 2592200
2021-10-07 16:20:18,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:18,854 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741828_1004 src: /172.19.0.2:40940 dest: /172.19.0.2:9866
2021-10-07 16:20:18,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40940, dest: /172.19.0.2:9866, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741828_1004, duration(ns): 1981200
2021-10-07 16:20:18,858 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:18,877 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741829_1005 src: /172.19.0.2:40942 dest: /172.19.0.2:9866
2021-10-07 16:20:18,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40942, dest: /172.19.0.2:9866, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741829_1005, duration(ns): 2705000
2021-10-07 16:20:18,882 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:19,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741830_1006 src: /172.19.0.2:40950 dest: /172.19.0.2:9866
2021-10-07 16:20:19,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40950, dest: /172.19.0.2:9866, bytes: 951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741830_1006, duration(ns): 3222700
2021-10-07 16:20:19,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:19,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741831_1007 src: /172.19.0.2:40952 dest: /172.19.0.2:9866
2021-10-07 16:20:19,332 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40952, dest: /172.19.0.2:9866, bytes: 2697, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741831_1007, duration(ns): 2382700
2021-10-07 16:20:19,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:19,351 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741832_1008 src: /172.19.0.2:40954 dest: /172.19.0.2:9866
2021-10-07 16:20:19,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40954, dest: /172.19.0.2:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741832_1008, duration(ns): 3340400
2021-10-07 16:20:19,357 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:19,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741833_1009 src: /172.19.0.2:40956 dest: /172.19.0.2:9866
2021-10-07 16:20:19,792 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40956, dest: /172.19.0.2:9866, bytes: 3880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741833_1009, duration(ns): 3395400
2021-10-07 16:20:19,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:19,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741834_1010 src: /172.19.0.2:40958 dest: /172.19.0.2:9866
2021-10-07 16:20:19,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40958, dest: /172.19.0.2:9866, bytes: 9213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741834_1010, duration(ns): 2947700
2021-10-07 16:20:19,820 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:20,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741835_1011 src: /172.19.0.2:40966 dest: /172.19.0.2:9866
2021-10-07 16:20:20,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40966, dest: /172.19.0.2:9866, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741835_1011, duration(ns): 3700700
2021-10-07 16:20:20,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:20,271 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741836_1012 src: /172.19.0.2:40968 dest: /172.19.0.2:9866
2021-10-07 16:20:20,275 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40968, dest: /172.19.0.2:9866, bytes: 983, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741836_1012, duration(ns): 2499500
2021-10-07 16:20:20,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:20,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741837_1013 src: /172.19.0.2:40970 dest: /172.19.0.2:9866
2021-10-07 16:20:20,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40970, dest: /172.19.0.2:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741837_1013, duration(ns): 2592300
2021-10-07 16:20:20,700 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,124 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741838_1014 src: /172.19.0.2:40972 dest: /172.19.0.2:9866
2021-10-07 16:20:21,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40972, dest: /172.19.0.2:9866, bytes: 6272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741838_1014, duration(ns): 4146900
2021-10-07 16:20:21,129 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741839_1015 src: /172.19.0.2:40974 dest: /172.19.0.2:9866
2021-10-07 16:20:21,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40974, dest: /172.19.0.2:9866, bytes: 3999, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741839_1015, duration(ns): 3746300
2021-10-07 16:20:21,156 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,177 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741840_1016 src: /172.19.0.2:40978 dest: /172.19.0.2:9866
2021-10-07 16:20:21,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40978, dest: /172.19.0.2:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741840_1016, duration(ns): 2390200
2021-10-07 16:20:21,181 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,202 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741841_1017 src: /172.19.0.2:40982 dest: /172.19.0.2:9866
2021-10-07 16:20:21,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40982, dest: /172.19.0.2:9866, bytes: 812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741841_1017, duration(ns): 3600300
2021-10-07 16:20:21,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741842_1018 src: /172.19.0.2:40984 dest: /172.19.0.2:9866
2021-10-07 16:20:21,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40984, dest: /172.19.0.2:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741842_1018, duration(ns): 3031500
2021-10-07 16:20:21,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741843_1019 src: /172.19.0.2:40988 dest: /172.19.0.2:9866
2021-10-07 16:20:21,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40988, dest: /172.19.0.2:9866, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741843_1019, duration(ns): 4114500
2021-10-07 16:20:21,257 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,278 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741844_1020 src: /172.19.0.2:40990 dest: /172.19.0.2:9866
2021-10-07 16:20:21,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40990, dest: /172.19.0.2:9866, bytes: 16287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741844_1020, duration(ns): 4717200
2021-10-07 16:20:21,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,305 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741845_1021 src: /172.19.0.2:40992 dest: /172.19.0.2:9866
2021-10-07 16:20:21,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40992, dest: /172.19.0.2:9866, bytes: 682, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741845_1021, duration(ns): 2231100
2021-10-07 16:20:21,309 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:21,730 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741846_1022 src: /172.19.0.2:40994 dest: /172.19.0.2:9866
2021-10-07 16:20:21,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40994, dest: /172.19.0.2:9866, bytes: 1040, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741846_1022, duration(ns): 4385200
2021-10-07 16:20:21,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:22,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741847_1023 src: /172.19.0.2:40998 dest: /172.19.0.2:9866
2021-10-07 16:20:22,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:40998, dest: /172.19.0.2:9866, bytes: 867, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741847_1023, duration(ns): 2609100
2021-10-07 16:20:22,162 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:22,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741848_1024 src: /172.19.0.2:41004 dest: /172.19.0.2:9866
2021-10-07 16:20:22,590 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41004, dest: /172.19.0.2:9866, bytes: 14713, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741848_1024, duration(ns): 3090200
2021-10-07 16:20:22,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:23,013 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741849_1025 src: /172.19.0.2:41006 dest: /172.19.0.2:9866
2021-10-07 16:20:23,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41006, dest: /172.19.0.2:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741849_1025, duration(ns): 3651400
2021-10-07 16:20:23,018 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:23,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741850_1026 src: /172.19.0.2:41014 dest: /172.19.0.2:9866
2021-10-07 16:20:23,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41014, dest: /172.19.0.2:9866, bytes: 1860, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741850_1026, duration(ns): 2482200
2021-10-07 16:20:23,443 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:23,864 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741851_1027 src: /172.19.0.2:41016 dest: /172.19.0.2:9866
2021-10-07 16:20:23,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41016, dest: /172.19.0.2:9866, bytes: 11392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741851_1027, duration(ns): 3207800
2021-10-07 16:20:23,869 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:24,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741852_1028 src: /172.19.0.2:41024 dest: /172.19.0.2:9866
2021-10-07 16:20:24,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41024, dest: /172.19.0.2:9866, bytes: 1940, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741852_1028, duration(ns): 3382000
2021-10-07 16:20:24,293 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:24,713 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741853_1029 src: /172.19.0.2:41026 dest: /172.19.0.2:9866
2021-10-07 16:20:24,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41026, dest: /172.19.0.2:9866, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741853_1029, duration(ns): 3400300
2021-10-07 16:20:24,718 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:24,736 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741854_1030 src: /172.19.0.2:41028 dest: /172.19.0.2:9866
2021-10-07 16:20:24,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41028, dest: /172.19.0.2:9866, bytes: 1764, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741854_1030, duration(ns): 2410700
2021-10-07 16:20:24,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:25,161 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741855_1031 src: /172.19.0.2:41030 dest: /172.19.0.2:9866
2021-10-07 16:20:25,165 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41030, dest: /172.19.0.2:9866, bytes: 2250, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741855_1031, duration(ns): 3108400
2021-10-07 16:20:25,166 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:25,586 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741856_1032 src: /172.19.0.2:41034 dest: /172.19.0.2:9866
2021-10-07 16:20:25,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41034, dest: /172.19.0.2:9866, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1081638599_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741856_1032, duration(ns): 2988700
2021-10-07 16:20:25,591 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:29,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 replica FinalizedReplica, blk_1073741833_1009, FINALIZED
  getNumBytes()     = 3880
  getBytesOnDisk()  = 3880
  getVisibleLength()= 3880
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-10-07 16:20:29,322 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-120179873-172.19.0.2-1633623595293 blk_1073741833_1009 URI file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741833
2021-10-07 16:20:29,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741857_1033 src: /172.19.0.2:41042 dest: /172.19.0.2:9866
2021-10-07 16:20:29,613 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41042, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1763209551_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741857_1033, duration(ns): 10300000
2021-10-07 16:20:29,614 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:29,738 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741858_1034 src: /172.19.0.2:41044 dest: /172.19.0.2:9866
2021-10-07 16:20:30,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41044, dest: /172.19.0.2:9866, bytes: 3621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1763209551_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741858_1034, duration(ns): 41577500
2021-10-07 16:20:30,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[172.19.0.3:9866, 172.19.0.5:9866, 172.19.0.4:9866] terminating
2021-10-07 16:20:30,083 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741859_1035 src: /172.19.0.2:41052 dest: /172.19.0.2:9866
2021-10-07 16:20:30,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41052, dest: /172.19.0.2:9866, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1763209551_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741859_1035, duration(ns): 1600400
2021-10-07 16:20:30,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:30,187 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741860_1036 src: /172.19.0.2:41054 dest: /172.19.0.2:9866
2021-10-07 16:20:30,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41054, dest: /172.19.0.2:9866, bytes: 200338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1763209551_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741860_1036, duration(ns): 4713200
2021-10-07 16:20:30,194 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:32,323 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.19.0.2:9866, datanodeUuid=df9c3895-b2fb-487d-9609-4ab82a050cb2, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-49f65dcc-f3ca-4aa8-b18f-993b6cb1b4f1;nsid=1538236608;c=1633623595293) Starting thread to transfer BP-120179873-172.19.0.2-1633623595293:blk_1073741857_1033 to 172.19.0.3:9866 172.19.0.4:9866 172.19.0.5:9866 
2021-10-07 16:20:32,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at host1:9866: Transmitted BP-120179873-172.19.0.2-1633623595293:blk_1073741857_1033 (numBytes=316483) to /172.19.0.3:9866
2021-10-07 16:20:35,412 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741861_1037 src: /172.19.0.2:41076 dest: /172.19.0.2:9866
2021-10-07 16:20:35,420 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41076, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_622985862_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741861_1037, duration(ns): 6547900
2021-10-07 16:20:35,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2021-10-07 16:20:45,483 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741862_1038 src: /172.19.0.2:41128 dest: /172.19.0.2:9866
2021-10-07 16:21:11,717 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741863_1039 src: /172.19.0.2:41434 dest: /172.19.0.2:9866
2021-10-07 16:21:11,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41434, dest: /172.19.0.2:9866, bytes: 49314, op: HDFS_WRITE, cliID: DFSClient_attempt_1633623608915_0001_r_000000_0_-2059114632_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741863_1039, duration(ns): 21170000
2021-10-07 16:21:11,740 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2021-10-07 16:21:11,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41128, dest: /172.19.0.2:9866, bytes: 136516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_622985862_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741862_1038, duration(ns): 26354716000
2021-10-07 16:21:11,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2021-10-07 16:21:11,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741864_1040 src: /172.19.0.2:41436 dest: /172.19.0.2:9866
2021-10-07 16:21:11,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41436, dest: /172.19.0.2:9866, bytes: 444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_622985862_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741864_1040, duration(ns): 2340900
2021-10-07 16:21:11,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2021-10-07 16:21:11,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741865_1041 src: /172.19.0.2:41440 dest: /172.19.0.2:9866
2021-10-07 16:21:11,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41440, dest: /172.19.0.2:9866, bytes: 136516, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_622985862_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741865_1041, duration(ns): 2059500
2021-10-07 16:21:11,890 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2021-10-07 16:21:11,911 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-120179873-172.19.0.2-1633623595293:blk_1073741866_1042 src: /172.19.0.2:41442 dest: /172.19.0.2:9866
2021-10-07 16:21:11,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41442, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_622985862_1, offset: 0, srvID: df9c3895-b2fb-487d-9609-4ab82a050cb2, blockid: BP-120179873-172.19.0.2-1633623595293:blk_1073741866_1042, duration(ns): 2380900
2021-10-07 16:21:11,915 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-120179873-172.19.0.2-1633623595293:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2021-10-07 16:21:17,318 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 replica FinalizedReplica, blk_1073741857_1033, FINALIZED
  getNumBytes()     = 316483
  getBytesOnDisk()  = 316483
  getVisibleLength()= 316483
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-10-07 16:21:17,318 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 replica FinalizedReplica, blk_1073741858_1034, FINALIZED
  getNumBytes()     = 3621
  getBytesOnDisk()  = 3621
  getVisibleLength()= 3621
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2021-10-07 16:21:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-120179873-172.19.0.2-1633623595293 blk_1073741857_1033 URI file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741857
2021-10-07 16:21:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 replica FinalizedReplica, blk_1073741859_1035, FINALIZED
  getNumBytes()     = 404
  getBytesOnDisk()  = 404
  getVisibleLength()= 404
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-10-07 16:21:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-120179873-172.19.0.2-1633623595293 blk_1073741858_1034 URI file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741858
2021-10-07 16:21:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 replica FinalizedReplica, blk_1073741860_1036, FINALIZED
  getNumBytes()     = 200338
  getBytesOnDisk()  = 200338
  getVisibleLength()= 200338
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-10-07 16:21:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-120179873-172.19.0.2-1633623595293 blk_1073741859_1035 URI file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741859
2021-10-07 16:21:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 replica FinalizedReplica, blk_1073741861_1037, FINALIZED
  getNumBytes()     = 231754
  getBytesOnDisk()  = 231754
  getVisibleLength()= 231754
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-10-07 16:21:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 replica FinalizedReplica, blk_1073741862_1038, FINALIZED
  getNumBytes()     = 136516
  getBytesOnDisk()  = 136516
  getVisibleLength()= 136516
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-10-07 16:21:17,319 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-120179873-172.19.0.2-1633623595293 blk_1073741860_1036 URI file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741860
2021-10-07 16:21:17,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-120179873-172.19.0.2-1633623595293 blk_1073741861_1037 URI file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741861
2021-10-07 16:21:17,320 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-120179873-172.19.0.2-1633623595293 blk_1073741862_1038 URI file:/root/hadoop/dfs/data/current/BP-120179873-172.19.0.2-1633623595293/current/finalized/subdir0/subdir0/blk_1073741862
2021-10-07 16:21:18,992 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2021-10-07 16:21:18,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at host1/172.19.0.2
************************************************************/
2021-10-07 16:27:08,132 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:27:08,146 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:27:08,694 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:27:08,833 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:27:08,950 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:27:08,951 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:27:09,297 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:27:09,319 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:27:09,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:27:09,334 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:27:09,339 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:27:09,367 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:27:09,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:27:09,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:27:09,443 INFO org.eclipse.jetty.util.log: Logging initialized @1982ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:27:09,597 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:27:09,610 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:27:09,624 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:27:09,627 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:27:09,627 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:27:09,627 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:27:09,680 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 34595
2021-10-07 16:27:09,683 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:27:09,868 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:27:09,868 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:27:09,870 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2021-10-07 16:27:09,886 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:27:09,887 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:27:09,966 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:27:09,979 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:27:10,000 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:34595}
2021-10-07 16:27:10,000 INFO org.eclipse.jetty.server.Server: Started @2540ms
2021-10-07 16:27:20,280 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:27:20,292 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:27:20,834 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:27:20,955 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:27:21,058 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:27:21,058 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:27:21,347 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:27:21,365 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:27:21,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:27:21,371 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:27:21,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:27:21,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:27:21,402 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:27:21,403 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:27:21,479 INFO org.eclipse.jetty.util.log: Logging initialized @1732ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:27:21,606 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:27:21,616 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:27:21,627 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:27:21,629 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:27:21,629 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:27:21,629 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:27:21,776 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 33103
2021-10-07 16:27:21,779 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:27:21,827 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:27:21,827 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:27:21,829 INFO org.eclipse.jetty.server.session: node0 Scavenging every 660000ms
2021-10-07 16:27:21,847 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:27:21,848 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7f284218{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:27:21,936 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:27:21,947 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@6d167f58{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:27:21,957 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:33103}
2021-10-07 16:27:21,957 INFO org.eclipse.jetty.server.Server: Started @2210ms
2021-10-07 16:27:22,182 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 16:27:22,190 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 16:27:22,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 16:27:22,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 16:27:22,254 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 16:27:22,275 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 16:27:22,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 16:27:22,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 16:27:22,626 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 16:27:22,673 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 16:27:22,719 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 16:27:22,723 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 16:27:23,036 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 16:27:23,039 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 16:27:23,046 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 400@host1
2021-10-07 16:27:23,047 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 1358561886. Formatting...
2021-10-07 16:27:23,048 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-9343ae27-fada-4112-b87a-f8d9e4524093 for directory /root/hadoop/dfs/data 
2021-10-07 16:27:23,081 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-2033316820-172.19.0.2-1633624036387
2021-10-07 16:27:23,082 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387
2021-10-07 16:27:23,082 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-2033316820-172.19.0.2-1633624036387 is not formatted. Formatting ...
2021-10-07 16:27:23,082 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-2033316820-172.19.0.2-1633624036387 directory /root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current
2021-10-07 16:27:23,087 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1358561886;bpid=BP-2033316820-172.19.0.2-1633624036387;lv=-57;nsInfo=lv=-65;cid=CID-358259cd-6477-4740-be47-cf7564a4a1cc;nsid=1358561886;c=1633624036387;bpid=BP-2033316820-172.19.0.2-1633624036387;dnuuid=null
2021-10-07 16:27:23,090 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 01ca13b5-c27c-4028-b6dc-c249ecab4482
2021-10-07 16:27:23,233 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-9343ae27-fada-4112-b87a-f8d9e4524093
2021-10-07 16:27:23,233 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 16:27:23,239 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 16:27:23,242 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 16:27:23,255 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-2033316820-172.19.0.2-1633624036387
2021-10-07 16:27:23,256 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-2033316820-172.19.0.2-1633624036387 on volume /root/hadoop/dfs/data...
2021-10-07 16:27:23,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-2033316820-172.19.0.2-1633624036387 on /root/hadoop/dfs/data: 51ms
2021-10-07 16:27:23,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-2033316820-172.19.0.2-1633624036387: 51ms
2021-10-07 16:27:23,314 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-2033316820-172.19.0.2-1633624036387 on volume /root/hadoop/dfs/data...
2021-10-07 16:27:23,314 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/replicas doesn't exist 
2021-10-07 16:27:23,321 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-2033316820-172.19.0.2-1633624036387 on volume /root/hadoop/dfs/data: 7ms
2021-10-07 16:27:23,321 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-2033316820-172.19.0.2-1633624036387: 12ms
2021-10-07 16:27:23,322 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 16:27:23,354 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 16:27:23,359 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-2033316820-172.19.0.2-1633624036387 on volume /root/hadoop/dfs/data
2021-10-07 16:27:23,362 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-9343ae27-fada-4112-b87a-f8d9e4524093): finished scanning block pool BP-2033316820-172.19.0.2-1633624036387
2021-10-07 16:27:23,376 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 4:58 PM with interval of 21600000ms
2021-10-07 16:27:23,377 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-9343ae27-fada-4112-b87a-f8d9e4524093): no suitable block pools found to scan.  Waiting 1814399981 ms.
2021-10-07 16:27:23,389 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-2033316820-172.19.0.2-1633624036387 (Datanode Uuid 01ca13b5-c27c-4028-b6dc-c249ecab4482) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 16:27:23,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-2033316820-172.19.0.2-1633624036387 (Datanode Uuid 01ca13b5-c27c-4028-b6dc-c249ecab4482) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 16:27:23,537 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 16:27:23,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x355ee3b9e375cd11,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 89 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 16:27:23,758 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-2033316820-172.19.0.2-1633624036387
2021-10-07 16:27:40,321 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741825_1001 src: /172.19.0.2:41678 dest: /172.19.0.2:9866
2021-10-07 16:27:40,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41678, dest: /172.19.0.2:9866, bytes: 1351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741825_1001, duration(ns): 15415500
2021-10-07 16:27:40,361 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:40,811 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741826_1002 src: /172.19.0.2:41680 dest: /172.19.0.2:9866
2021-10-07 16:27:40,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41680, dest: /172.19.0.2:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741826_1002, duration(ns): 3414400
2021-10-07 16:27:40,817 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:41,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741827_1003 src: /172.19.0.2:41688 dest: /172.19.0.2:9866
2021-10-07 16:27:41,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41688, dest: /172.19.0.2:9866, bytes: 3321, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741827_1003, duration(ns): 3556900
2021-10-07 16:27:41,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:41,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741828_1004 src: /172.19.0.2:41690 dest: /172.19.0.2:9866
2021-10-07 16:27:41,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41690, dest: /172.19.0.2:9866, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741828_1004, duration(ns): 4527400
2021-10-07 16:27:41,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:41,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741829_1005 src: /172.19.0.2:41692 dest: /172.19.0.2:9866
2021-10-07 16:27:41,313 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41692, dest: /172.19.0.2:9866, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741829_1005, duration(ns): 2418800
2021-10-07 16:27:41,314 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:41,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741830_1006 src: /172.19.0.2:41694 dest: /172.19.0.2:9866
2021-10-07 16:27:41,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41694, dest: /172.19.0.2:9866, bytes: 951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741830_1006, duration(ns): 2363600
2021-10-07 16:27:41,341 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:41,363 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741831_1007 src: /172.19.0.2:41696 dest: /172.19.0.2:9866
2021-10-07 16:27:41,368 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41696, dest: /172.19.0.2:9866, bytes: 2697, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741831_1007, duration(ns): 3286300
2021-10-07 16:27:41,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:41,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741832_1008 src: /172.19.0.2:41698 dest: /172.19.0.2:9866
2021-10-07 16:27:41,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41698, dest: /172.19.0.2:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741832_1008, duration(ns): 3536100
2021-10-07 16:27:41,395 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:41,423 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741833_1009 src: /172.19.0.2:41700 dest: /172.19.0.2:9866
2021-10-07 16:27:41,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41700, dest: /172.19.0.2:9866, bytes: 3880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741833_1009, duration(ns): 2630600
2021-10-07 16:27:41,428 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:41,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741834_1010 src: /172.19.0.2:41704 dest: /172.19.0.2:9866
2021-10-07 16:27:41,855 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41704, dest: /172.19.0.2:9866, bytes: 9213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741834_1010, duration(ns): 3041700
2021-10-07 16:27:41,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:42,277 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741835_1011 src: /172.19.0.2:41710 dest: /172.19.0.2:9866
2021-10-07 16:27:42,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41710, dest: /172.19.0.2:9866, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741835_1011, duration(ns): 2600900
2021-10-07 16:27:42,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:42,303 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741836_1012 src: /172.19.0.2:41712 dest: /172.19.0.2:9866
2021-10-07 16:27:42,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41712, dest: /172.19.0.2:9866, bytes: 983, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741836_1012, duration(ns): 2415900
2021-10-07 16:27:42,308 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:42,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741837_1013 src: /172.19.0.2:41714 dest: /172.19.0.2:9866
2021-10-07 16:27:42,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41714, dest: /172.19.0.2:9866, bytes: 24, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741837_1013, duration(ns): 2514600
2021-10-07 16:27:42,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:42,755 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741838_1014 src: /172.19.0.2:41716 dest: /172.19.0.2:9866
2021-10-07 16:27:42,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41716, dest: /172.19.0.2:9866, bytes: 6272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741838_1014, duration(ns): 3235400
2021-10-07 16:27:42,760 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,182 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741839_1015 src: /172.19.0.2:41724 dest: /172.19.0.2:9866
2021-10-07 16:27:43,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41724, dest: /172.19.0.2:9866, bytes: 3999, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741839_1015, duration(ns): 3863900
2021-10-07 16:27:43,188 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741840_1016 src: /172.19.0.2:41726 dest: /172.19.0.2:9866
2021-10-07 16:27:43,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41726, dest: /172.19.0.2:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741840_1016, duration(ns): 3708800
2021-10-07 16:27:43,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,244 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741841_1017 src: /172.19.0.2:41728 dest: /172.19.0.2:9866
2021-10-07 16:27:43,251 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41728, dest: /172.19.0.2:9866, bytes: 812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741841_1017, duration(ns): 5429700
2021-10-07 16:27:43,252 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,276 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741842_1018 src: /172.19.0.2:41730 dest: /172.19.0.2:9866
2021-10-07 16:27:43,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41730, dest: /172.19.0.2:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741842_1018, duration(ns): 5609600
2021-10-07 16:27:43,284 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,307 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741843_1019 src: /172.19.0.2:41732 dest: /172.19.0.2:9866
2021-10-07 16:27:43,311 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41732, dest: /172.19.0.2:9866, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741843_1019, duration(ns): 3313900
2021-10-07 16:27:43,312 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,331 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741844_1020 src: /172.19.0.2:41734 dest: /172.19.0.2:9866
2021-10-07 16:27:43,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41734, dest: /172.19.0.2:9866, bytes: 16287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741844_1020, duration(ns): 3047800
2021-10-07 16:27:43,335 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,352 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741845_1021 src: /172.19.0.2:41736 dest: /172.19.0.2:9866
2021-10-07 16:27:43,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41736, dest: /172.19.0.2:9866, bytes: 682, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741845_1021, duration(ns): 2091100
2021-10-07 16:27:43,356 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741846_1022 src: /172.19.0.2:41738 dest: /172.19.0.2:9866
2021-10-07 16:27:43,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41738, dest: /172.19.0.2:9866, bytes: 1040, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741846_1022, duration(ns): 1881800
2021-10-07 16:27:43,378 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,804 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741847_1023 src: /172.19.0.2:41740 dest: /172.19.0.2:9866
2021-10-07 16:27:43,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41740, dest: /172.19.0.2:9866, bytes: 867, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741847_1023, duration(ns): 2142900
2021-10-07 16:27:43,808 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,830 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741848_1024 src: /172.19.0.2:41742 dest: /172.19.0.2:9866
2021-10-07 16:27:43,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41742, dest: /172.19.0.2:9866, bytes: 14713, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741848_1024, duration(ns): 2841900
2021-10-07 16:27:43,836 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:43,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741849_1025 src: /172.19.0.2:41746 dest: /172.19.0.2:9866
2021-10-07 16:27:43,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41746, dest: /172.19.0.2:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741849_1025, duration(ns): 3336400
2021-10-07 16:27:43,863 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:44,283 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741850_1026 src: /172.19.0.2:41752 dest: /172.19.0.2:9866
2021-10-07 16:27:44,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41752, dest: /172.19.0.2:9866, bytes: 1860, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741850_1026, duration(ns): 2642800
2021-10-07 16:27:44,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:44,707 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741851_1027 src: /172.19.0.2:41754 dest: /172.19.0.2:9866
2021-10-07 16:27:44,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41754, dest: /172.19.0.2:9866, bytes: 11392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741851_1027, duration(ns): 2837400
2021-10-07 16:27:44,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:45,133 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741852_1028 src: /172.19.0.2:41762 dest: /172.19.0.2:9866
2021-10-07 16:27:45,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41762, dest: /172.19.0.2:9866, bytes: 1940, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741852_1028, duration(ns): 2770400
2021-10-07 16:27:45,138 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:45,559 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741853_1029 src: /172.19.0.2:41766 dest: /172.19.0.2:9866
2021-10-07 16:27:45,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41766, dest: /172.19.0.2:9866, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741853_1029, duration(ns): 3367000
2021-10-07 16:27:45,565 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:45,985 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741854_1030 src: /172.19.0.2:41770 dest: /172.19.0.2:9866
2021-10-07 16:27:45,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41770, dest: /172.19.0.2:9866, bytes: 1764, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741854_1030, duration(ns): 2558900
2021-10-07 16:27:45,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:46,410 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741855_1031 src: /172.19.0.2:41776 dest: /172.19.0.2:9866
2021-10-07 16:27:46,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41776, dest: /172.19.0.2:9866, bytes: 2250, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741855_1031, duration(ns): 2449800
2021-10-07 16:27:46,415 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:46,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741856_1032 src: /172.19.0.2:41780 dest: /172.19.0.2:9866
2021-10-07 16:27:46,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41780, dest: /172.19.0.2:9866, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-34736020_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741856_1032, duration(ns): 2946300
2021-10-07 16:27:46,839 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:50,552 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 replica FinalizedReplica, blk_1073741833_1009, FINALIZED
  getNumBytes()     = 3880
  getBytesOnDisk()  = 3880
  getVisibleLength()= 3880
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-10-07 16:27:50,555 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2033316820-172.19.0.2-1633624036387 blk_1073741833_1009 URI file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741833
2021-10-07 16:27:50,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741857_1033 src: /172.19.0.2:41800 dest: /172.19.0.2:9866
2021-10-07 16:27:51,014 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41800, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1158253163_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741857_1033, duration(ns): 18674300
2021-10-07 16:27:51,015 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:51,152 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741858_1034 src: /172.19.0.2:41802 dest: /172.19.0.2:9866
2021-10-07 16:27:51,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41802, dest: /172.19.0.2:9866, bytes: 3621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1158253163_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741858_1034, duration(ns): 45731300
2021-10-07 16:27:51,533 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=3:[172.19.0.5:9866, 172.19.0.4:9866, 172.19.0.3:9866] terminating
2021-10-07 16:27:51,553 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741859_1035 src: /172.19.0.2:41812 dest: /172.19.0.2:9866
2021-10-07 16:27:51,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41812, dest: /172.19.0.2:9866, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1158253163_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741859_1035, duration(ns): 2856600
2021-10-07 16:27:51,558 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:51,686 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741860_1036 src: /172.19.0.2:41814 dest: /172.19.0.2:9866
2021-10-07 16:27:51,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41814, dest: /172.19.0.2:9866, bytes: 200338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1158253163_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741860_1036, duration(ns): 6826600
2021-10-07 16:27:51,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2021-10-07 16:27:53,554 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.19.0.2:9866, datanodeUuid=01ca13b5-c27c-4028-b6dc-c249ecab4482, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-358259cd-6477-4740-be47-cf7564a4a1cc;nsid=1358561886;c=1633624036387) Starting thread to transfer BP-2033316820-172.19.0.2-1633624036387:blk_1073741857_1033 to 172.19.0.4:9866 172.19.0.5:9866 172.19.0.3:9866 
2021-10-07 16:27:53,571 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at host1:9866: Transmitted BP-2033316820-172.19.0.2-1633624036387:blk_1073741857_1033 (numBytes=316483) to /172.19.0.4:9866
2021-10-07 16:27:57,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741861_1037 src: /172.19.0.2:41858 dest: /172.19.0.2:9866
2021-10-07 16:27:57,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41858, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_116711642_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741861_1037, duration(ns): 10509500
2021-10-07 16:27:57,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2021-10-07 16:28:03,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741862_1038 src: /172.19.0.2:41908 dest: /172.19.0.2:9866
2021-10-07 16:28:28,373 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741863_1039 src: /172.19.0.2:42246 dest: /172.19.0.2:9866
2021-10-07 16:28:28,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:42246, dest: /172.19.0.2:9866, bytes: 49314, op: HDFS_WRITE, cliID: DFSClient_attempt_1633624050552_0001_r_000000_0_778534736_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741863_1039, duration(ns): 14863600
2021-10-07 16:28:28,391 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2021-10-07 16:28:28,485 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:41908, dest: /172.19.0.2:9866, bytes: 136163, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_116711642_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741862_1038, duration(ns): 25092582200
2021-10-07 16:28:28,486 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2021-10-07 16:28:28,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741864_1040 src: /172.19.0.2:42248 dest: /172.19.0.2:9866
2021-10-07 16:28:28,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:42248, dest: /172.19.0.2:9866, bytes: 444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_116711642_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741864_1040, duration(ns): 2806700
2021-10-07 16:28:28,907 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2021-10-07 16:28:29,337 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741865_1041 src: /172.19.0.2:42252 dest: /172.19.0.2:9866
2021-10-07 16:28:29,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:42252, dest: /172.19.0.2:9866, bytes: 136163, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_116711642_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741865_1041, duration(ns): 3323900
2021-10-07 16:28:29,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2021-10-07 16:28:29,365 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-2033316820-172.19.0.2-1633624036387:blk_1073741866_1042 src: /172.19.0.2:42254 dest: /172.19.0.2:9866
2021-10-07 16:28:29,370 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:42254, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_116711642_1, offset: 0, srvID: 01ca13b5-c27c-4028-b6dc-c249ecab4482, blockid: BP-2033316820-172.19.0.2-1633624036387:blk_1073741866_1042, duration(ns): 2882500
2021-10-07 16:28:29,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-2033316820-172.19.0.2-1633624036387:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2021-10-07 16:28:35,545 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 replica FinalizedReplica, blk_1073741857_1033, FINALIZED
  getNumBytes()     = 316483
  getBytesOnDisk()  = 316483
  getVisibleLength()= 316483
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-10-07 16:28:35,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 replica FinalizedReplica, blk_1073741858_1034, FINALIZED
  getNumBytes()     = 3621
  getBytesOnDisk()  = 3621
  getVisibleLength()= 3621
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2021-10-07 16:28:35,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 replica FinalizedReplica, blk_1073741859_1035, FINALIZED
  getNumBytes()     = 404
  getBytesOnDisk()  = 404
  getVisibleLength()= 404
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-10-07 16:28:35,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2033316820-172.19.0.2-1633624036387 blk_1073741857_1033 URI file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741857
2021-10-07 16:28:35,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 replica FinalizedReplica, blk_1073741860_1036, FINALIZED
  getNumBytes()     = 200338
  getBytesOnDisk()  = 200338
  getVisibleLength()= 200338
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-10-07 16:28:35,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2033316820-172.19.0.2-1633624036387 blk_1073741858_1034 URI file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741858
2021-10-07 16:28:35,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 replica FinalizedReplica, blk_1073741861_1037, FINALIZED
  getNumBytes()     = 231754
  getBytesOnDisk()  = 231754
  getVisibleLength()= 231754
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-10-07 16:28:35,546 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2033316820-172.19.0.2-1633624036387 blk_1073741859_1035 URI file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741859
2021-10-07 16:28:35,547 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2033316820-172.19.0.2-1633624036387 blk_1073741860_1036 URI file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741860
2021-10-07 16:28:35,547 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 replica FinalizedReplica, blk_1073741862_1038, FINALIZED
  getNumBytes()     = 136163
  getBytesOnDisk()  = 136163
  getVisibleLength()= 136163
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-10-07 16:28:35,547 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2033316820-172.19.0.2-1633624036387 blk_1073741861_1037 URI file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741861
2021-10-07 16:28:35,547 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-2033316820-172.19.0.2-1633624036387 blk_1073741862_1038 URI file:/root/hadoop/dfs/data/current/BP-2033316820-172.19.0.2-1633624036387/current/finalized/subdir0/subdir0/blk_1073741862
2021-10-07 16:29:16,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:29:16,330 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:29:18,664 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:29:19,275 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:29:19,780 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:29:19,780 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:29:22,411 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:29:22,575 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:29:22,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:29:22,628 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:29:22,642 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:29:22,964 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:29:22,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:29:22,968 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:29:23,654 INFO org.eclipse.jetty.util.log: Logging initialized @8927ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:29:25,097 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:29:25,192 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:29:25,239 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:29:25,244 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:29:25,244 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:29:25,245 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:29:25,375 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44779
2021-10-07 16:29:25,377 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:29:26,612 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:29:26,612 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:29:26,616 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2021-10-07 16:29:26,747 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d94beb9{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:29:26,750 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:29:27,504 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:29:27,551 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@3bd323e9{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:29:27,574 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@1e4d3ce5{HTTP/1.1,[http/1.1]}{localhost:44779}
2021-10-07 16:29:27,575 INFO org.eclipse.jetty.server.Server: Started @12852ms
2021-10-07 16:29:28,992 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 16:29:29,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 16:29:29,030 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 16:29:29,073 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 16:29:29,460 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 16:29:29,621 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 16:29:32,860 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 16:29:33,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 16:29:33,294 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 16:29:33,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 16:29:33,537 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 16:29:33,584 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 16:29:35,255 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 16:29:35,298 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 16:29:35,582 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 405@host1
2021-10-07 16:29:35,584 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 1378428168. Formatting...
2021-10-07 16:29:35,586 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-530cda28-5a4a-4c36-8d1f-063c1c45d777 for directory /root/hadoop/dfs/data 
2021-10-07 16:29:35,835 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-989515759-172.19.0.2-1633624151047
2021-10-07 16:29:35,835 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-989515759-172.19.0.2-1633624151047
2021-10-07 16:29:35,836 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-989515759-172.19.0.2-1633624151047 is not formatted. Formatting ...
2021-10-07 16:29:35,836 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-989515759-172.19.0.2-1633624151047 directory /root/hadoop/dfs/data/current/BP-989515759-172.19.0.2-1633624151047/current
2021-10-07 16:29:35,874 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1378428168;bpid=BP-989515759-172.19.0.2-1633624151047;lv=-57;nsInfo=lv=-65;cid=CID-95d985da-5d72-4cdf-bd0a-a9ed908ab98d;nsid=1378428168;c=1633624151047;bpid=BP-989515759-172.19.0.2-1633624151047;dnuuid=null
2021-10-07 16:29:35,900 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 961bf3eb-eec5-4a41-ac41-612b2a0698ed
2021-10-07 16:29:36,321 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-530cda28-5a4a-4c36-8d1f-063c1c45d777
2021-10-07 16:29:36,330 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 16:29:36,338 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 16:29:36,359 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 16:29:36,390 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-989515759-172.19.0.2-1633624151047
2021-10-07 16:29:36,402 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-989515759-172.19.0.2-1633624151047 on volume /root/hadoop/dfs/data...
2021-10-07 16:29:36,550 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-989515759-172.19.0.2-1633624151047 on /root/hadoop/dfs/data: 139ms
2021-10-07 16:29:36,550 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-989515759-172.19.0.2-1633624151047: 159ms
2021-10-07 16:29:36,563 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-989515759-172.19.0.2-1633624151047 on volume /root/hadoop/dfs/data...
2021-10-07 16:29:36,573 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-989515759-172.19.0.2-1633624151047/current/replicas doesn't exist 
2021-10-07 16:29:36,583 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-989515759-172.19.0.2-1633624151047 on volume /root/hadoop/dfs/data: 14ms
2021-10-07 16:29:36,583 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-989515759-172.19.0.2-1633624151047: 31ms
2021-10-07 16:29:36,585 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 16:29:36,620 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 16:29:36,634 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-989515759-172.19.0.2-1633624151047 on volume /root/hadoop/dfs/data
2021-10-07 16:29:36,637 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-530cda28-5a4a-4c36-8d1f-063c1c45d777): finished scanning block pool BP-989515759-172.19.0.2-1633624151047
2021-10-07 16:29:36,670 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-530cda28-5a4a-4c36-8d1f-063c1c45d777): no suitable block pools found to scan.  Waiting 1814399963 ms.
2021-10-07 16:29:36,674 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 9:06 PM with interval of 21600000ms
2021-10-07 16:29:36,695 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-989515759-172.19.0.2-1633624151047 (Datanode Uuid 961bf3eb-eec5-4a41-ac41-612b2a0698ed) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 16:29:36,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-989515759-172.19.0.2-1633624151047 (Datanode Uuid 961bf3eb-eec5-4a41-ac41-612b2a0698ed) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 16:29:36,739 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 16:29:36,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x2facdaa620003406,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 49 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 16:29:36,891 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-989515759-172.19.0.2-1633624151047
2021-10-07 16:29:44,517 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1135ms
No GCs detected
2021-10-07 16:29:55,579 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 10561ms
No GCs detected
2021-10-07 16:29:58,092 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1511ms
No GCs detected
2021-10-07 16:30:11,961 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 13368ms
No GCs detected
2021-10-07 16:30:53,306 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 40842ms
No GCs detected
2021-10-07 16:31:34,179 WARN org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 30986ms
No GCs detected
2021-10-07 16:31:35,798 INFO org.apache.hadoop.util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1118ms
No GCs detected
2021-10-07 16:34:21,078 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:34:21,288 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:34:44,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-07 16:34:44,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-07 16:34:44,936 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-07 16:34:45,106 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-07 16:34:45,241 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-07 16:34:45,241 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-07 16:34:45,693 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:34:45,719 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-07 16:34:45,729 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-07 16:34:45,729 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-07 16:34:45,735 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-07 16:34:45,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-07 16:34:45,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-07 16:34:45,774 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-07 16:34:45,883 INFO org.eclipse.jetty.util.log: Logging initialized @2515ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-07 16:34:46,168 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-07 16:34:46,187 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-07 16:34:46,204 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-07 16:34:46,208 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-07 16:34:46,208 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-07 16:34:46,208 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-07 16:34:46,256 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35535
2021-10-07 16:34:46,258 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-07 16:34:46,525 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-07 16:34:46,525 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-07 16:34:46,529 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2021-10-07 16:34:46,554 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f1c29b7{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-07 16:34:46,556 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ea5b703{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-07 16:34:46,669 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-07 16:34:46,685 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@65b104b9{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-07 16:34:46,700 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@1acaf3d{HTTP/1.1,[http/1.1]}{localhost:35535}
2021-10-07 16:34:46,701 INFO org.eclipse.jetty.server.Server: Started @3333ms
2021-10-07 16:34:47,001 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-07 16:34:47,019 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-07 16:34:47,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-07 16:34:47,025 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-07 16:34:47,098 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-07 16:34:47,136 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-07 16:34:47,530 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-07 16:34:47,555 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-07 16:34:47,570 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-07 16:34:47,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-07 16:34:47,600 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-07 16:34:47,603 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-07 16:34:47,787 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-07 16:34:47,791 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-07 16:34:47,798 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 402@host1
2021-10-07 16:34:47,799 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 450375088. Formatting...
2021-10-07 16:34:47,800 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-f364fe01-5d06-4509-91e8-f05b889723b2 for directory /root/hadoop/dfs/data 
2021-10-07 16:34:47,831 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-453579069-172.19.0.2-1633624479732
2021-10-07 16:34:47,831 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732
2021-10-07 16:34:47,832 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-453579069-172.19.0.2-1633624479732 is not formatted. Formatting ...
2021-10-07 16:34:47,832 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-453579069-172.19.0.2-1633624479732 directory /root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current
2021-10-07 16:34:47,843 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=450375088;bpid=BP-453579069-172.19.0.2-1633624479732;lv=-57;nsInfo=lv=-65;cid=CID-d1b44cf3-832a-4556-9515-5daf04bbb60d;nsid=450375088;c=1633624479732;bpid=BP-453579069-172.19.0.2-1633624479732;dnuuid=null
2021-10-07 16:34:47,847 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 9844c37f-13c1-4fc0-9190-378d8bf702ee
2021-10-07 16:34:48,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-f364fe01-5d06-4509-91e8-f05b889723b2
2021-10-07 16:34:48,029 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-07 16:34:48,039 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-07 16:34:48,043 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-07 16:34:48,067 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-453579069-172.19.0.2-1633624479732
2021-10-07 16:34:48,069 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-453579069-172.19.0.2-1633624479732 on volume /root/hadoop/dfs/data...
2021-10-07 16:34:48,203 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-453579069-172.19.0.2-1633624479732 on /root/hadoop/dfs/data: 131ms
2021-10-07 16:34:48,203 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-453579069-172.19.0.2-1633624479732: 137ms
2021-10-07 16:34:48,270 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-453579069-172.19.0.2-1633624479732 on volume /root/hadoop/dfs/data...
2021-10-07 16:34:48,270 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/replicas doesn't exist 
2021-10-07 16:34:48,304 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-453579069-172.19.0.2-1633624479732 on volume /root/hadoop/dfs/data: 34ms
2021-10-07 16:34:48,307 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-453579069-172.19.0.2-1633624479732: 44ms
2021-10-07 16:34:48,308 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-07 16:34:48,328 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-07 16:34:48,332 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-453579069-172.19.0.2-1633624479732 on volume /root/hadoop/dfs/data
2021-10-07 16:34:48,335 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-f364fe01-5d06-4509-91e8-f05b889723b2): finished scanning block pool BP-453579069-172.19.0.2-1633624479732
2021-10-07 16:34:48,363 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-f364fe01-5d06-4509-91e8-f05b889723b2): no suitable block pools found to scan.  Waiting 1814399969 ms.
2021-10-07 16:34:48,383 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/7/21 7:02 PM with interval of 21600000ms
2021-10-07 16:34:48,430 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-453579069-172.19.0.2-1633624479732 (Datanode Uuid 9844c37f-13c1-4fc0-9190-378d8bf702ee) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-07 16:34:48,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-453579069-172.19.0.2-1633624479732 (Datanode Uuid 9844c37f-13c1-4fc0-9190-378d8bf702ee) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-07 16:34:48,514 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-07 16:34:48,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7df964ae1ab4ea7b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 7 msec to generate and 115 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 16:34:48,781 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-453579069-172.19.0.2-1633624479732
2021-10-07 16:35:06,784 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741825_1001 src: /172.19.0.2:34818 dest: /172.19.0.2:9866
2021-10-07 16:35:06,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34818, dest: /172.19.0.2:9866, bytes: 1351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741825_1001, duration(ns): 13380400
2021-10-07 16:35:06,821 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:07,266 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741826_1002 src: /172.19.0.2:34822 dest: /172.19.0.2:9866
2021-10-07 16:35:07,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34822, dest: /172.19.0.2:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741826_1002, duration(ns): 1791500
2021-10-07 16:35:07,270 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:07,692 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741827_1003 src: /172.19.0.2:34830 dest: /172.19.0.2:9866
2021-10-07 16:35:07,696 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34830, dest: /172.19.0.2:9866, bytes: 3321, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741827_1003, duration(ns): 2413600
2021-10-07 16:35:07,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:07,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741828_1004 src: /172.19.0.2:34832 dest: /172.19.0.2:9866
2021-10-07 16:35:07,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34832, dest: /172.19.0.2:9866, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741828_1004, duration(ns): 2059700
2021-10-07 16:35:07,719 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:08,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741829_1005 src: /172.19.0.2:34834 dest: /172.19.0.2:9866
2021-10-07 16:35:08,148 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34834, dest: /172.19.0.2:9866, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741829_1005, duration(ns): 2490600
2021-10-07 16:35:08,149 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:08,170 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741830_1006 src: /172.19.0.2:34836 dest: /172.19.0.2:9866
2021-10-07 16:35:08,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34836, dest: /172.19.0.2:9866, bytes: 951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741830_1006, duration(ns): 2103900
2021-10-07 16:35:08,174 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:08,192 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741831_1007 src: /172.19.0.2:34838 dest: /172.19.0.2:9866
2021-10-07 16:35:08,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34838, dest: /172.19.0.2:9866, bytes: 2697, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741831_1007, duration(ns): 3206200
2021-10-07 16:35:08,197 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:08,216 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741832_1008 src: /172.19.0.2:34840 dest: /172.19.0.2:9866
2021-10-07 16:35:08,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34840, dest: /172.19.0.2:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741832_1008, duration(ns): 1426500
2021-10-07 16:35:08,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:08,241 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741833_1009 src: /172.19.0.2:34842 dest: /172.19.0.2:9866
2021-10-07 16:35:08,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34842, dest: /172.19.0.2:9866, bytes: 3880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741833_1009, duration(ns): 2138000
2021-10-07 16:35:08,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:08,264 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741834_1010 src: /172.19.0.2:34846 dest: /172.19.0.2:9866
2021-10-07 16:35:08,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34846, dest: /172.19.0.2:9866, bytes: 9213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741834_1010, duration(ns): 2191300
2021-10-07 16:35:08,268 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:08,689 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741835_1011 src: /172.19.0.2:34854 dest: /172.19.0.2:9866
2021-10-07 16:35:08,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34854, dest: /172.19.0.2:9866, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741835_1011, duration(ns): 2392100
2021-10-07 16:35:08,694 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:09,118 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741836_1012 src: /172.19.0.2:34856 dest: /172.19.0.2:9866
2021-10-07 16:35:09,122 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34856, dest: /172.19.0.2:9866, bytes: 983, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741836_1012, duration(ns): 2466300
2021-10-07 16:35:09,123 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:09,545 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741837_1013 src: /172.19.0.2:34864 dest: /172.19.0.2:9866
2021-10-07 16:35:09,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34864, dest: /172.19.0.2:9866, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741837_1013, duration(ns): 3910600
2021-10-07 16:35:09,550 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:09,568 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741838_1014 src: /172.19.0.2:34868 dest: /172.19.0.2:9866
2021-10-07 16:35:09,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34868, dest: /172.19.0.2:9866, bytes: 6272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741838_1014, duration(ns): 4316700
2021-10-07 16:35:09,574 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:09,994 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741839_1015 src: /172.19.0.2:34870 dest: /172.19.0.2:9866
2021-10-07 16:35:09,998 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34870, dest: /172.19.0.2:9866, bytes: 3999, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741839_1015, duration(ns): 2619900
2021-10-07 16:35:09,999 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:10,020 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741840_1016 src: /172.19.0.2:34872 dest: /172.19.0.2:9866
2021-10-07 16:35:10,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34872, dest: /172.19.0.2:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741840_1016, duration(ns): 2605200
2021-10-07 16:35:10,025 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:10,045 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741841_1017 src: /172.19.0.2:34874 dest: /172.19.0.2:9866
2021-10-07 16:35:10,049 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34874, dest: /172.19.0.2:9866, bytes: 812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741841_1017, duration(ns): 3162200
2021-10-07 16:35:10,050 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:10,067 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741842_1018 src: /172.19.0.2:34876 dest: /172.19.0.2:9866
2021-10-07 16:35:10,071 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34876, dest: /172.19.0.2:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741842_1018, duration(ns): 2961500
2021-10-07 16:35:10,072 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:10,089 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741843_1019 src: /172.19.0.2:34878 dest: /172.19.0.2:9866
2021-10-07 16:35:10,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34878, dest: /172.19.0.2:9866, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741843_1019, duration(ns): 3900000
2021-10-07 16:35:10,094 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:10,515 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741844_1020 src: /172.19.0.2:34886 dest: /172.19.0.2:9866
2021-10-07 16:35:10,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34886, dest: /172.19.0.2:9866, bytes: 16287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741844_1020, duration(ns): 2671900
2021-10-07 16:35:10,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:10,939 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741845_1021 src: /172.19.0.2:34890 dest: /172.19.0.2:9866
2021-10-07 16:35:10,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34890, dest: /172.19.0.2:9866, bytes: 682, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741845_1021, duration(ns): 2977600
2021-10-07 16:35:10,944 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:11,366 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741846_1022 src: /172.19.0.2:34894 dest: /172.19.0.2:9866
2021-10-07 16:35:11,371 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34894, dest: /172.19.0.2:9866, bytes: 1040, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741846_1022, duration(ns): 3173800
2021-10-07 16:35:11,372 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:11,793 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741847_1023 src: /172.19.0.2:34902 dest: /172.19.0.2:9866
2021-10-07 16:35:11,797 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34902, dest: /172.19.0.2:9866, bytes: 867, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741847_1023, duration(ns): 2753100
2021-10-07 16:35:11,798 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:12,215 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741848_1024 src: /172.19.0.2:34904 dest: /172.19.0.2:9866
2021-10-07 16:35:12,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34904, dest: /172.19.0.2:9866, bytes: 14713, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741848_1024, duration(ns): 2231400
2021-10-07 16:35:12,219 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:12,640 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741849_1025 src: /172.19.0.2:34914 dest: /172.19.0.2:9866
2021-10-07 16:35:12,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34914, dest: /172.19.0.2:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741849_1025, duration(ns): 2282700
2021-10-07 16:35:12,644 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:13,065 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741850_1026 src: /172.19.0.2:34916 dest: /172.19.0.2:9866
2021-10-07 16:35:13,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34916, dest: /172.19.0.2:9866, bytes: 1860, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741850_1026, duration(ns): 2866400
2021-10-07 16:35:13,070 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:13,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741851_1027 src: /172.19.0.2:34918 dest: /172.19.0.2:9866
2021-10-07 16:35:13,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34918, dest: /172.19.0.2:9866, bytes: 11392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741851_1027, duration(ns): 2079600
2021-10-07 16:35:13,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:13,913 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741852_1028 src: /172.19.0.2:34920 dest: /172.19.0.2:9866
2021-10-07 16:35:13,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34920, dest: /172.19.0.2:9866, bytes: 1940, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741852_1028, duration(ns): 2316600
2021-10-07 16:35:13,918 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:14,338 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741853_1029 src: /172.19.0.2:34922 dest: /172.19.0.2:9866
2021-10-07 16:35:14,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34922, dest: /172.19.0.2:9866, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741853_1029, duration(ns): 2679300
2021-10-07 16:35:14,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:14,362 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741854_1030 src: /172.19.0.2:34924 dest: /172.19.0.2:9866
2021-10-07 16:35:14,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34924, dest: /172.19.0.2:9866, bytes: 1764, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741854_1030, duration(ns): 1720400
2021-10-07 16:35:14,364 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:14,381 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741855_1031 src: /172.19.0.2:34926 dest: /172.19.0.2:9866
2021-10-07 16:35:14,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34926, dest: /172.19.0.2:9866, bytes: 2250, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741855_1031, duration(ns): 1727100
2021-10-07 16:35:14,384 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:14,401 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741856_1032 src: /172.19.0.2:34928 dest: /172.19.0.2:9866
2021-10-07 16:35:14,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34928, dest: /172.19.0.2:9866, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_683031068_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741856_1032, duration(ns): 2085200
2021-10-07 16:35:14,404 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:18,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741857_1033 src: /172.19.0.2:34936 dest: /172.19.0.2:9866
2021-10-07 16:35:18,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34936, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_297742134_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741857_1033, duration(ns): 9230200
2021-10-07 16:35:18,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:18,390 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741858_1034 src: /172.19.0.2:34938 dest: /172.19.0.2:9866
2021-10-07 16:35:18,530 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 replica FinalizedReplica, blk_1073741833_1009, FINALIZED
  getNumBytes()     = 3880
  getBytesOnDisk()  = 3880
  getVisibleLength()= 3880
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-10-07 16:35:18,531 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-453579069-172.19.0.2-1633624479732 blk_1073741833_1009 URI file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741833
2021-10-07 16:35:18,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34938, dest: /172.19.0.2:9866, bytes: 3621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_297742134_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741858_1034, duration(ns): 50410700
2021-10-07 16:35:18,840 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[172.19.0.5:9866, 172.19.0.6:9866, 172.19.0.4:9866, 172.19.0.3:9866] terminating
2021-10-07 16:35:18,856 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741859_1035 src: /172.19.0.2:34948 dest: /172.19.0.2:9866
2021-10-07 16:35:18,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34948, dest: /172.19.0.2:9866, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_297742134_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741859_1035, duration(ns): 1268000
2021-10-07 16:35:18,859 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:19,000 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741860_1036 src: /172.19.0.2:34950 dest: /172.19.0.2:9866
2021-10-07 16:35:19,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34950, dest: /172.19.0.2:9866, bytes: 200338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_297742134_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741860_1036, duration(ns): 4945800
2021-10-07 16:35:19,009 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:21,529 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.19.0.2:9866, datanodeUuid=9844c37f-13c1-4fc0-9190-378d8bf702ee, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-d1b44cf3-832a-4556-9515-5daf04bbb60d;nsid=450375088;c=1633624479732) Starting thread to transfer BP-453579069-172.19.0.2-1633624479732:blk_1073741857_1033 to 172.19.0.5:9866 172.19.0.3:9866 172.19.0.4:9866 172.19.0.6:9866 
2021-10-07 16:35:21,538 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at host1:9866: Transmitted BP-453579069-172.19.0.2-1633624479732:blk_1073741857_1033 (numBytes=316483) to /172.19.0.5:9866
2021-10-07 16:35:25,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741861_1037 src: /172.19.0.2:34974 dest: /172.19.0.2:9866
2021-10-07 16:35:25,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:34974, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-314515115_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741861_1037, duration(ns): 8532200
2021-10-07 16:35:25,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:31,991 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741862_1038 src: /172.19.0.2:35028 dest: /172.19.0.2:9866
2021-10-07 16:35:59,100 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741863_1039 src: /172.19.0.2:35386 dest: /172.19.0.2:9866
2021-10-07 16:35:59,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:35386, dest: /172.19.0.2:9866, bytes: 49322, op: HDFS_WRITE, cliID: DFSClient_attempt_1633624495407_0001_r_000000_0_-675563516_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741863_1039, duration(ns): 9908200
2021-10-07 16:35:59,111 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:59,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:35028, dest: /172.19.0.2:9866, bytes: 136306, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-314515115_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741862_1038, duration(ns): 27197666600
2021-10-07 16:35:59,201 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:59,214 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741864_1040 src: /172.19.0.2:35388 dest: /172.19.0.2:9866
2021-10-07 16:35:59,217 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:35388, dest: /172.19.0.2:9866, bytes: 444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-314515115_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741864_1040, duration(ns): 1889500
2021-10-07 16:35:59,218 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:59,247 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741865_1041 src: /172.19.0.2:35392 dest: /172.19.0.2:9866
2021-10-07 16:35:59,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:35392, dest: /172.19.0.2:9866, bytes: 136306, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-314515115_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741865_1041, duration(ns): 1764100
2021-10-07 16:35:59,258 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2021-10-07 16:35:59,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-453579069-172.19.0.2-1633624479732:blk_1073741866_1042 src: /172.19.0.2:35394 dest: /172.19.0.2:9866
2021-10-07 16:35:59,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:35394, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-314515115_1, offset: 0, srvID: 9844c37f-13c1-4fc0-9190-378d8bf702ee, blockid: BP-453579069-172.19.0.2-1633624479732:blk_1073741866_1042, duration(ns): 2904100
2021-10-07 16:35:59,287 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-453579069-172.19.0.2-1633624479732:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2021-10-07 16:36:06,526 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 replica FinalizedReplica, blk_1073741857_1033, FINALIZED
  getNumBytes()     = 316483
  getBytesOnDisk()  = 316483
  getVisibleLength()= 316483
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 replica FinalizedReplica, blk_1073741858_1034, FINALIZED
  getNumBytes()     = 3621
  getBytesOnDisk()  = 3621
  getVisibleLength()= 3621
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 replica FinalizedReplica, blk_1073741859_1035, FINALIZED
  getNumBytes()     = 404
  getBytesOnDisk()  = 404
  getVisibleLength()= 404
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-453579069-172.19.0.2-1633624479732 blk_1073741857_1033 URI file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741857
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 replica FinalizedReplica, blk_1073741860_1036, FINALIZED
  getNumBytes()     = 200338
  getBytesOnDisk()  = 200338
  getVisibleLength()= 200338
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-453579069-172.19.0.2-1633624479732 blk_1073741858_1034 URI file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741858
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 replica FinalizedReplica, blk_1073741861_1037, FINALIZED
  getNumBytes()     = 231754
  getBytesOnDisk()  = 231754
  getVisibleLength()= 231754
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-453579069-172.19.0.2-1633624479732 blk_1073741859_1035 URI file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741859
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 replica FinalizedReplica, blk_1073741862_1038, FINALIZED
  getNumBytes()     = 136306
  getBytesOnDisk()  = 136306
  getVisibleLength()= 136306
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-453579069-172.19.0.2-1633624479732 blk_1073741860_1036 URI file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741860
2021-10-07 16:36:06,527 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-453579069-172.19.0.2-1633624479732 blk_1073741861_1037 URI file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741861
2021-10-07 16:36:06,528 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-453579069-172.19.0.2-1633624479732 blk_1073741862_1038 URI file:/root/hadoop/dfs/data/current/BP-453579069-172.19.0.2-1633624479732/current/finalized/subdir0/subdir0/blk_1073741862
2021-10-07 17:56:22,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7df964ae1ab4ea7c,  containing 1 storage report(s), of which we sent 1. The reports had 35 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 17:56:22,475 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-453579069-172.19.0.2-1633624479732
2021-10-07 19:02:04,392 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: BlockPool BP-453579069-172.19.0.2-1633624479732 Total blocks: 35, missing metadata files:0, missing block files:0, missing blocks in memory:0, mismatched blocks:0
2021-10-07 23:56:22,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x7df964ae1ab4ea7d,  containing 1 storage report(s), of which we sent 1. The reports had 35 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-07 23:56:22,697 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-453579069-172.19.0.2-1633624479732
2021-10-08 00:36:35,959 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = host1/172.19.0.2
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.2.2
STARTUP_MSG:   classpath = /hadoop/etc/hadoop:/hadoop/share/hadoop/common/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/common/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/common/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/common/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/common/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/common/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/common/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/share/hadoop/common/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/common/lib/commons-text-1.4.jar:/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/common/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/common/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/common/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/common/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2-tests.jar:/hadoop/share/hadoop/common/hadoop-nfs-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-kms-3.2.2.jar:/hadoop/share/hadoop/common/hadoop-common-3.2.2.jar:/hadoop/share/hadoop/hdfs:/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/commons-compress-1.19.jar:/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.9.10.jar:/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.48.Final.jar:/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.9.10.4.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.2.2.jar:/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-text-1.4.jar:/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/hadoop/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-7.9.jar:/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/share/hadoop/hdfs/lib/javax.activation-api-1.2.0.jar:/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.20.v20190813.jar:/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.2-tests.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.2.jar:/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.2.2-tests.jar:/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.2.jar:/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.2-tests.jar:/hadoop/share/hadoop/yarn:/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.10.jar:/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-submarine-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.2.jar:/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.2.jar
STARTUP_MSG:   build = Unknown -r 7a3bc90b05f257c8ace2f76d74264906f0f7a932; compiled by 'hexiaoqiao' on 2021-01-03T09:26Z
STARTUP_MSG:   java = 1.8.0_292
************************************************************/
2021-10-08 00:36:35,975 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2021-10-08 00:36:36,704 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/root/hadoop/dfs/data
2021-10-08 00:36:36,898 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2021-10-08 00:36:37,096 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2021-10-08 00:36:37,096 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2021-10-08 00:36:37,774 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-08 00:36:37,801 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2021-10-08 00:36:37,810 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is host1
2021-10-08 00:36:37,810 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2021-10-08 00:36:37,816 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2021-10-08 00:36:37,866 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2021-10-08 00:36:37,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2021-10-08 00:36:37,870 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2021-10-08 00:36:38,068 INFO org.eclipse.jetty.util.log: Logging initialized @3257ms to org.eclipse.jetty.util.log.Slf4jLog
2021-10-08 00:36:38,309 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2021-10-08 00:36:38,327 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2021-10-08 00:36:38,353 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2021-10-08 00:36:38,358 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2021-10-08 00:36:38,358 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2021-10-08 00:36:38,358 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2021-10-08 00:36:38,405 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 44827
2021-10-08 00:36:38,406 INFO org.eclipse.jetty.server.Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: 84700530e645e812b336747464d6fbbf370c9a20; jvm 1.8.0_292-8u292-b10-0ubuntu1~20.04-b10
2021-10-08 00:36:38,570 INFO org.eclipse.jetty.server.session: DefaultSessionIdManager workerName=node0
2021-10-08 00:36:38,570 INFO org.eclipse.jetty.server.session: No SessionScavenger set, using defaults
2021-10-08 00:36:38,575 INFO org.eclipse.jetty.server.session: node0 Scavenging every 600000ms
2021-10-08 00:36:38,600 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7d94beb9{logs,/logs,file:///hadoop/logs/,AVAILABLE}
2021-10-08 00:36:38,601 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7b993c65{static,/static,file:///hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2021-10-08 00:36:38,726 INFO org.eclipse.jetty.util.TypeUtil: JVM Runtime does not support Modules
2021-10-08 00:36:38,746 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@3bd323e9{datanode,/,file:///hadoop/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{file:/hadoop/share/hadoop/hdfs/webapps/datanode}
2021-10-08 00:36:38,766 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@1e4d3ce5{HTTP/1.1,[http/1.1]}{localhost:44827}
2021-10-08 00:36:38,766 INFO org.eclipse.jetty.server.Server: Started @3955ms
2021-10-08 00:36:39,146 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2021-10-08 00:36:39,159 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2021-10-08 00:36:39,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2021-10-08 00:36:39,164 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2021-10-08 00:36:39,242 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2021-10-08 00:36:39,266 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2021-10-08 00:36:39,679 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2021-10-08 00:36:39,715 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2021-10-08 00:36:39,737 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2021-10-08 00:36:39,765 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000 starting to offer service
2021-10-08 00:36:39,783 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2021-10-08 00:36:39,796 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2021-10-08 00:36:40,002 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to host1/172.19.0.2:9000
2021-10-08 00:36:40,008 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2021-10-08 00:36:40,017 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /root/hadoop/dfs/data/in_use.lock acquired by nodename 372@host1
2021-10-08 00:36:40,020 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/root/hadoop/dfs/data is not formatted for namespace 110829934. Formatting...
2021-10-08 00:36:40,022 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-49903013-4b28-4743-ae9a-0b001c5175b8 for directory /root/hadoop/dfs/data 
2021-10-08 00:36:40,081 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-1266625790-172.19.0.2-1633653391149
2021-10-08 00:36:40,082 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149
2021-10-08 00:36:40,083 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/root/hadoop/dfs/data and block pool id BP-1266625790-172.19.0.2-1633653391149 is not formatted. Formatting ...
2021-10-08 00:36:40,083 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-1266625790-172.19.0.2-1633653391149 directory /root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current
2021-10-08 00:36:40,095 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=110829934;bpid=BP-1266625790-172.19.0.2-1633653391149;lv=-57;nsInfo=lv=-65;cid=CID-2c3a5297-b19f-47c1-985f-a111903e7a38;nsid=110829934;c=1633653391149;bpid=BP-1266625790-172.19.0.2-1633653391149;dnuuid=null
2021-10-08 00:36:40,102 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 29fee537-0076-4849-814f-4dee90df603e
2021-10-08 00:36:40,448 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-49903013-4b28-4743-ae9a-0b001c5175b8
2021-10-08 00:36:40,449 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/root/hadoop/dfs/data, StorageType: DISK
2021-10-08 00:36:40,465 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.MemoryMappableBlockLoader: Initializing cache loader: MemoryMappableBlockLoader.
2021-10-08 00:36:40,482 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2021-10-08 00:36:40,497 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-1266625790-172.19.0.2-1633653391149
2021-10-08 00:36:40,515 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-1266625790-172.19.0.2-1633653391149 on volume /root/hadoop/dfs/data...
2021-10-08 00:36:40,717 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-1266625790-172.19.0.2-1633653391149 on /root/hadoop/dfs/data: 202ms
2021-10-08 00:36:40,718 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1266625790-172.19.0.2-1633653391149: 220ms
2021-10-08 00:36:40,726 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-1266625790-172.19.0.2-1633653391149 on volume /root/hadoop/dfs/data...
2021-10-08 00:36:40,731 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/replicas doesn't exist 
2021-10-08 00:36:40,764 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1266625790-172.19.0.2-1633653391149 on volume /root/hadoop/dfs/data: 34ms
2021-10-08 00:36:40,765 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-1266625790-172.19.0.2-1633653391149: 45ms
2021-10-08 00:36:40,765 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /root/hadoop/dfs/data
2021-10-08 00:36:40,812 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /root/hadoop/dfs/data
2021-10-08 00:36:40,816 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-1266625790-172.19.0.2-1633653391149 on volume /root/hadoop/dfs/data
2021-10-08 00:36:40,819 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-49903013-4b28-4743-ae9a-0b001c5175b8): finished scanning block pool BP-1266625790-172.19.0.2-1633653391149
2021-10-08 00:36:40,925 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/root/hadoop/dfs/data, DS-49903013-4b28-4743-ae9a-0b001c5175b8): no suitable block pools found to scan.  Waiting 1814399891 ms.
2021-10-08 00:36:40,933 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 10/8/21 5:20 AM with interval of 21600000ms
2021-10-08 00:36:40,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-1266625790-172.19.0.2-1633653391149 (Datanode Uuid 29fee537-0076-4849-814f-4dee90df603e) service to host1/172.19.0.2:9000 beginning handshake with NN
2021-10-08 00:36:41,206 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-1266625790-172.19.0.2-1633653391149 (Datanode Uuid 29fee537-0076-4849-814f-4dee90df603e) service to host1/172.19.0.2:9000 successfully registered with NN
2021-10-08 00:36:41,207 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode host1/172.19.0.2:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2021-10-08 00:36:41,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x8258a29f57de728b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 242 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2021-10-08 00:36:41,745 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-1266625790-172.19.0.2-1633653391149
2021-10-08 00:37:04,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741825_1001 src: /172.19.0.2:39110 dest: /172.19.0.2:9866
2021-10-08 00:37:04,611 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39110, dest: /172.19.0.2:9866, bytes: 1351, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741825_1001, duration(ns): 15683100
2021-10-08 00:37:04,612 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:05,058 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741826_1002 src: /172.19.0.2:39116 dest: /172.19.0.2:9866
2021-10-08 00:37:05,062 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39116, dest: /172.19.0.2:9866, bytes: 1484, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741826_1002, duration(ns): 2860800
2021-10-08 00:37:05,063 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:05,082 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741827_1003 src: /172.19.0.2:39118 dest: /172.19.0.2:9866
2021-10-08 00:37:05,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39118, dest: /172.19.0.2:9866, bytes: 3321, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741827_1003, duration(ns): 2089600
2021-10-08 00:37:05,086 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:05,105 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741828_1004 src: /172.19.0.2:39120 dest: /172.19.0.2:9866
2021-10-08 00:37:05,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39120, dest: /172.19.0.2:9866, bytes: 2316, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741828_1004, duration(ns): 1887800
2021-10-08 00:37:05,110 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:05,130 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741829_1005 src: /172.19.0.2:39122 dest: /172.19.0.2:9866
2021-10-08 00:37:05,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39122, dest: /172.19.0.2:9866, bytes: 4113, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741829_1005, duration(ns): 2146400
2021-10-08 00:37:05,135 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:05,154 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741830_1006 src: /172.19.0.2:39124 dest: /172.19.0.2:9866
2021-10-08 00:37:05,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39124, dest: /172.19.0.2:9866, bytes: 951, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741830_1006, duration(ns): 1993100
2021-10-08 00:37:05,157 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:05,575 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741831_1007 src: /172.19.0.2:39130 dest: /172.19.0.2:9866
2021-10-08 00:37:05,579 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39130, dest: /172.19.0.2:9866, bytes: 2697, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741831_1007, duration(ns): 2310500
2021-10-08 00:37:05,580 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:05,598 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741832_1008 src: /172.19.0.2:39132 dest: /172.19.0.2:9866
2021-10-08 00:37:05,601 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39132, dest: /172.19.0.2:9866, bytes: 2591, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741832_1008, duration(ns): 1843500
2021-10-08 00:37:05,602 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:06,029 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741833_1009 src: /172.19.0.2:39138 dest: /172.19.0.2:9866
2021-10-08 00:37:06,032 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39138, dest: /172.19.0.2:9866, bytes: 3880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741833_1009, duration(ns): 1658100
2021-10-08 00:37:06,033 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:06,452 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741834_1010 src: /172.19.0.2:39144 dest: /172.19.0.2:9866
2021-10-08 00:37:06,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39144, dest: /172.19.0.2:9866, bytes: 9213, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741834_1010, duration(ns): 2095700
2021-10-08 00:37:06,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:06,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741835_1011 src: /172.19.0.2:39146 dest: /172.19.0.2:9866
2021-10-08 00:37:06,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39146, dest: /172.19.0.2:9866, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741835_1011, duration(ns): 2208600
2021-10-08 00:37:06,478 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:06,499 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741836_1012 src: /172.19.0.2:39148 dest: /172.19.0.2:9866
2021-10-08 00:37:06,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39148, dest: /172.19.0.2:9866, bytes: 983, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741836_1012, duration(ns): 2290000
2021-10-08 00:37:06,503 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:06,521 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741837_1013 src: /172.19.0.2:39150 dest: /172.19.0.2:9866
2021-10-08 00:37:06,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39150, dest: /172.19.0.2:9866, bytes: 30, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741837_1013, duration(ns): 2007500
2021-10-08 00:37:06,525 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:06,543 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741838_1014 src: /172.19.0.2:39152 dest: /172.19.0.2:9866
2021-10-08 00:37:06,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39152, dest: /172.19.0.2:9866, bytes: 6272, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741838_1014, duration(ns): 2371100
2021-10-08 00:37:06,548 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:06,564 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741839_1015 src: /172.19.0.2:39154 dest: /172.19.0.2:9866
2021-10-08 00:37:06,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39154, dest: /172.19.0.2:9866, bytes: 3999, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741839_1015, duration(ns): 2054200
2021-10-08 00:37:06,567 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:06,989 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741840_1016 src: /172.19.0.2:39160 dest: /172.19.0.2:9866
2021-10-08 00:37:06,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39160, dest: /172.19.0.2:9866, bytes: 1657, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741840_1016, duration(ns): 2215900
2021-10-08 00:37:06,993 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:07,418 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741841_1017 src: /172.19.0.2:39166 dest: /172.19.0.2:9866
2021-10-08 00:37:07,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39166, dest: /172.19.0.2:9866, bytes: 812, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741841_1017, duration(ns): 4790100
2021-10-08 00:37:07,426 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:07,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741842_1018 src: /172.19.0.2:39168 dest: /172.19.0.2:9866
2021-10-08 00:37:07,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39168, dest: /172.19.0.2:9866, bytes: 3414, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741842_1018, duration(ns): 2994700
2021-10-08 00:37:07,480 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:07,902 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741843_1019 src: /172.19.0.2:39174 dest: /172.19.0.2:9866
2021-10-08 00:37:07,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39174, dest: /172.19.0.2:9866, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741843_1019, duration(ns): 4014900
2021-10-08 00:37:07,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:07,929 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741844_1020 src: /172.19.0.2:39176 dest: /172.19.0.2:9866
2021-10-08 00:37:07,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39176, dest: /172.19.0.2:9866, bytes: 16287, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741844_1020, duration(ns): 3260900
2021-10-08 00:37:07,934 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:07,956 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741845_1021 src: /172.19.0.2:39178 dest: /172.19.0.2:9866
2021-10-08 00:37:07,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39178, dest: /172.19.0.2:9866, bytes: 682, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741845_1021, duration(ns): 4152300
2021-10-08 00:37:07,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:07,983 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741846_1022 src: /172.19.0.2:39180 dest: /172.19.0.2:9866
2021-10-08 00:37:07,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39180, dest: /172.19.0.2:9866, bytes: 1040, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741846_1022, duration(ns): 3132600
2021-10-08 00:37:07,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:08,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741847_1023 src: /172.19.0.2:39182 dest: /172.19.0.2:9866
2021-10-08 00:37:08,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39182, dest: /172.19.0.2:9866, bytes: 867, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741847_1023, duration(ns): 2473300
2021-10-08 00:37:08,012 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:08,433 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741848_1024 src: /172.19.0.2:39188 dest: /172.19.0.2:9866
2021-10-08 00:37:08,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39188, dest: /172.19.0.2:9866, bytes: 14713, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741848_1024, duration(ns): 2655700
2021-10-08 00:37:08,438 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:08,857 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741849_1025 src: /172.19.0.2:39194 dest: /172.19.0.2:9866
2021-10-08 00:37:08,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39194, dest: /172.19.0.2:9866, bytes: 2642, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741849_1025, duration(ns): 2431000
2021-10-08 00:37:08,861 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:08,880 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741850_1026 src: /172.19.0.2:39196 dest: /172.19.0.2:9866
2021-10-08 00:37:08,885 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39196, dest: /172.19.0.2:9866, bytes: 1860, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741850_1026, duration(ns): 2960500
2021-10-08 00:37:08,886 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:08,904 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741851_1027 src: /172.19.0.2:39198 dest: /172.19.0.2:9866
2021-10-08 00:37:08,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39198, dest: /172.19.0.2:9866, bytes: 11392, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741851_1027, duration(ns): 2477700
2021-10-08 00:37:08,908 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:09,329 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741852_1028 src: /172.19.0.2:39204 dest: /172.19.0.2:9866
2021-10-08 00:37:09,333 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39204, dest: /172.19.0.2:9866, bytes: 1940, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741852_1028, duration(ns): 3032800
2021-10-08 00:37:09,334 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:09,353 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741853_1029 src: /172.19.0.2:39206 dest: /172.19.0.2:9866
2021-10-08 00:37:09,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39206, dest: /172.19.0.2:9866, bytes: 1335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741853_1029, duration(ns): 3082700
2021-10-08 00:37:09,358 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:09,376 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741854_1030 src: /172.19.0.2:39208 dest: /172.19.0.2:9866
2021-10-08 00:37:09,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39208, dest: /172.19.0.2:9866, bytes: 1764, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741854_1030, duration(ns): 2156900
2021-10-08 00:37:09,380 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:09,396 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741855_1031 src: /172.19.0.2:39210 dest: /172.19.0.2:9866
2021-10-08 00:37:09,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39210, dest: /172.19.0.2:9866, bytes: 2250, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741855_1031, duration(ns): 1809100
2021-10-08 00:37:09,400 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:09,416 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741856_1032 src: /172.19.0.2:39212 dest: /172.19.0.2:9866
2021-10-08 00:37:09,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39212, dest: /172.19.0.2:9866, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-396261300_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741856_1032, duration(ns): 2834900
2021-10-08 00:37:09,421 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:13,573 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741857_1033 src: /172.19.0.2:39236 dest: /172.19.0.2:9866
2021-10-08 00:37:13,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39236, dest: /172.19.0.2:9866, bytes: 316483, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_302388454_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741857_1033, duration(ns): 10033100
2021-10-08 00:37:13,585 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:13,741 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741858_1034 src: /172.19.0.2:39238 dest: /172.19.0.2:9866
2021-10-08 00:37:14,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39238, dest: /172.19.0.2:9866, bytes: 3621, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_302388454_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741858_1034, duration(ns): 53690500
2021-10-08 00:37:14,224 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=4:[172.19.0.5:9866, 172.19.0.3:9866, 172.19.0.6:9866, 172.19.0.4:9866] terminating
2021-10-08 00:37:14,245 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741859_1035 src: /172.19.0.2:39248 dest: /172.19.0.2:9866
2021-10-08 00:37:14,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39248, dest: /172.19.0.2:9866, bytes: 404, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_302388454_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741859_1035, duration(ns): 1676100
2021-10-08 00:37:14,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DatanodeRegistration(172.19.0.2:9866, datanodeUuid=29fee537-0076-4849-814f-4dee90df603e, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-2c3a5297-b19f-47c1-985f-a111903e7a38;nsid=110829934;c=1633653391149) Starting thread to transfer BP-1266625790-172.19.0.2-1633653391149:blk_1073741857_1033 to 172.19.0.5:9866 172.19.0.6:9866 172.19.0.4:9866 172.19.0.3:9866 
2021-10-08 00:37:14,249 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:14,253 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741833_1009 replica FinalizedReplica, blk_1073741833_1009, FINALIZED
  getNumBytes()     = 3880
  getBytesOnDisk()  = 3880
  getVisibleLength()= 3880
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741833 for deletion
2021-10-08 00:37:14,255 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1266625790-172.19.0.2-1633653391149 blk_1073741833_1009 URI file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741833
2021-10-08 00:37:14,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: DataTransfer, at host1:9866: Transmitted BP-1266625790-172.19.0.2-1633653391149:blk_1073741857_1033 (numBytes=316483) to /172.19.0.5:9866
2021-10-08 00:37:14,771 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741860_1036 src: /172.19.0.2:39258 dest: /172.19.0.2:9866
2021-10-08 00:37:14,778 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39258, dest: /172.19.0.2:9866, bytes: 200338, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_302388454_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741860_1036, duration(ns): 4538200
2021-10-08 00:37:14,779 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:21,269 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741861_1037 src: /172.19.0.2:39286 dest: /172.19.0.2:9866
2021-10-08 00:37:21,285 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39286, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2010693207_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741861_1037, duration(ns): 13957900
2021-10-08 00:37:21,286 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:28,605 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741862_1038 src: /172.19.0.2:39338 dest: /172.19.0.2:9866
2021-10-08 00:37:57,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741863_1039 src: /172.19.0.2:39706 dest: /172.19.0.2:9866
2021-10-08 00:37:57,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39706, dest: /172.19.0.2:9866, bytes: 49322, op: HDFS_WRITE, cliID: DFSClient_attempt_1633653410369_0001_r_000000_0_139302780_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741863_1039, duration(ns): 12765400
2021-10-08 00:37:57,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:57,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39338, dest: /172.19.0.2:9866, bytes: 136278, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2010693207_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741862_1038, duration(ns): 28627839000
2021-10-08 00:37:57,238 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:57,250 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741864_1040 src: /172.19.0.2:39708 dest: /172.19.0.2:9866
2021-10-08 00:37:57,253 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39708, dest: /172.19.0.2:9866, bytes: 444, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2010693207_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741864_1040, duration(ns): 2140600
2021-10-08 00:37:57,254 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:57,279 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741865_1041 src: /172.19.0.2:39712 dest: /172.19.0.2:9866
2021-10-08 00:37:57,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39712, dest: /172.19.0.2:9866, bytes: 136278, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2010693207_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741865_1041, duration(ns): 1789000
2021-10-08 00:37:57,282 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2021-10-08 00:37:57,301 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-1266625790-172.19.0.2-1633653391149:blk_1073741866_1042 src: /172.19.0.2:39714 dest: /172.19.0.2:9866
2021-10-08 00:37:57,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /172.19.0.2:39714, dest: /172.19.0.2:9866, bytes: 231754, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2010693207_1, offset: 0, srvID: 29fee537-0076-4849-814f-4dee90df603e, blockid: BP-1266625790-172.19.0.2-1633653391149:blk_1073741866_1042, duration(ns): 1826100
2021-10-08 00:37:57,304 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-1266625790-172.19.0.2-1633653391149:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2021-10-08 00:38:02,224 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741857_1033 replica FinalizedReplica, blk_1073741857_1033, FINALIZED
  getNumBytes()     = 316483
  getBytesOnDisk()  = 316483
  getVisibleLength()= 316483
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741857 for deletion
2021-10-08 00:38:02,224 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741858_1034 replica FinalizedReplica, blk_1073741858_1034, FINALIZED
  getNumBytes()     = 3621
  getBytesOnDisk()  = 3621
  getVisibleLength()= 3621
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741858 for deletion
2021-10-08 00:38:02,224 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741859_1035 replica FinalizedReplica, blk_1073741859_1035, FINALIZED
  getNumBytes()     = 404
  getBytesOnDisk()  = 404
  getVisibleLength()= 404
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741859 for deletion
2021-10-08 00:38:02,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1266625790-172.19.0.2-1633653391149 blk_1073741857_1033 URI file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741857
2021-10-08 00:38:02,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741860_1036 replica FinalizedReplica, blk_1073741860_1036, FINALIZED
  getNumBytes()     = 200338
  getBytesOnDisk()  = 200338
  getVisibleLength()= 200338
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741860 for deletion
2021-10-08 00:38:02,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1266625790-172.19.0.2-1633653391149 blk_1073741858_1034 URI file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741858
2021-10-08 00:38:02,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741861_1037 replica FinalizedReplica, blk_1073741861_1037, FINALIZED
  getNumBytes()     = 231754
  getBytesOnDisk()  = 231754
  getVisibleLength()= 231754
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741861 for deletion
2021-10-08 00:38:02,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1266625790-172.19.0.2-1633653391149 blk_1073741859_1035 URI file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741859
2021-10-08 00:38:02,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741862_1038 replica FinalizedReplica, blk_1073741862_1038, FINALIZED
  getNumBytes()     = 136278
  getBytesOnDisk()  = 136278
  getVisibleLength()= 136278
  getVolume()       = /root/hadoop/dfs/data
  getBlockURI()     = file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741862 for deletion
2021-10-08 00:38:02,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1266625790-172.19.0.2-1633653391149 blk_1073741860_1036 URI file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741860
2021-10-08 00:38:02,225 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1266625790-172.19.0.2-1633653391149 blk_1073741861_1037 URI file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741861
2021-10-08 00:38:02,226 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-1266625790-172.19.0.2-1633653391149 blk_1073741862_1038 URI file:/root/hadoop/dfs/data/current/BP-1266625790-172.19.0.2-1633653391149/current/finalized/subdir0/subdir0/blk_1073741862
